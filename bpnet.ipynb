{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQzUIPis5nvr"
   },
   "source": [
    "# Overview\n",
    "\n",
    "This tutorial will show you how to:\n",
    "  1. Train BPNet\n",
    "  2. Compute contribution scores\n",
    "  3. Discover motifs with TF-MoDISco\n",
    "  4. Determine motif instances with CWM scanning\n",
    "  5. Simulate motif spacing\n",
    "  \n",
    "\n",
    "This will be done on a subset of the data from the [BPNet paper](https://www.biorxiv.org/content/biorxiv/early/2019/08/21/737981.full.pdf) measuring TF binding of 3/4 TFs (Oct4, Sox2, and Nanog) with ChIP-nexus in mouse embryonic stem cells (mESCs). To make things faster, we will only use peak regions from chromosomes 2, 16, 17, 18 and 19 to train/evaluate the model and run TF-MoDISco (**10% of the original data**).\n",
    "\n",
    "We'll be using the `bpnet` python package to accomplish these steps. You can find out more about it at https://github.com/kundajelab/bpnet.\n",
    "\n",
    "Use the 'Table of contents' on the left to navigate this notebook. If you have any suggestions or questions, you can add comments to the individual cells using the Ctrl+Alt+M shortcut.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wrXYiIsH5GrT"
   },
   "source": [
    "## Setup\n",
    "\n",
    "Make sure you have enabled the GPU runtime by navigating to the menu 'Runtime', select 'Change runtime type' and set the runtime to 'GPU'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRuPISG391E3"
   },
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u_5mSHbhNCVk",
    "outputId": "f820d9e1-c2b6-4267-86a4-3610486425bd"
   },
   "outputs": [],
   "source": [
    "# !pip uninstall tensorflow -y\n",
    "\n",
    "# !pip install tensorflow==1.14.0\n",
    "\n",
    "\n",
    "# NOTE: after running this, restart the runtime: Runtime -> Restart runtime -> yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iZ_AdEo2AuAy",
    "outputId": "cbc7db96-7ecf-403b-b1a9-20a276e371b5"
   },
   "outputs": [],
   "source": [
    "# !pip install pprint -i https://pypi.doubanio.com/simple/ --trusted-host pypi.douban.com\n",
    "# !pip install bpnet --quiet --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uaasVD8e-PZK",
    "outputId": "f11362a5-efe3-4f9f-fcea-99258b07df93"
   },
   "outputs": [],
   "source": [
    "# !apt-get install -y bedtools > /dev/null\n",
    "# !pip install git+https://github.com/kundajelab/DeepExplain.git --quiet\n",
    "# !pip install -U cloudpickle h5py tqdm --quiet\n",
    "# !pip install -U pyyaml --quiet\n",
    "# !pip install bpnet --quiet --quiet\n",
    "# !pip install -U jupyter_client>=6.1.2 --quiet\n",
    "# !pip install wandb snakemake --quiet\n",
    "\n",
    "# %env HDF5_USE_FILE_LOCKING=FALSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UkrcPqUt7vut"
   },
   "source": [
    "If you are running this on your own machine, please see the installation intructions at https://github.com/kundajelab/bpnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "id": "75gZh6kYpZ01",
    "outputId": "c0ae3f31-bc63-4c39-b2a3-577c206479c6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-13 21:04:23,720 [WARNING] From /home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %tensorflow_version 1.x\n",
    "import bpnet\n",
    "from bpnet.cli.contrib import ContribFile\n",
    "from bpnet.plot.tracks import plot_tracks, to_neg\n",
    "\n",
    "import uuid\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BUMU-vxK7Qqr"
   },
   "source": [
    "#### Optional: Setup wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "Pay9JFgR3YNi",
    "outputId": "b3ab8413-40e1-45ed-d4d0-ba5e2e002298"
   },
   "outputs": [],
   "source": [
    "# Uncomment if you would like to run this notebook using Wandb\n",
    "\n",
    "# import wandb\n",
    "# wandb.init(project='bpnet-demo', entity='avsec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6HeGNlu95RW"
   },
   "source": [
    "### Get test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "k_tFgH1y-dq-",
    "outputId": "d352f037-86a3-4c7c-d1e1-657e9b74808c"
   },
   "outputs": [],
   "source": [
    "# # Dowload and extract the bpnet repo\n",
    "# !wget 'https://drive.google.com/uc?authuser=0&id=1YX1svzlRnLtvxyzj5O4B1l5-_wArZ9Q6&export=download' -O bpnet.tar.gz\n",
    "# !tar xvfz bpnet.tar.gz  > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0US826Pr5KY",
    "outputId": "172bf65b-71b2-40dd-c8a7-e8304063482a"
   },
   "outputs": [],
   "source": [
    "# # Download chip_nexus data\n",
    "# !snakemake -d bpnet/examples -s bpnet/examples/Snakefile chip_nexus -j 4 --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1h1KHdzb0Bnm"
   },
   "source": [
    "# Train BPNet\n",
    "\n",
    "<img src=\"https://github.com/kundajelab/bpnet/blob/master/notebooks/figs/bpnet-arch.png?raw=1\" alt=\"BPNet\" style=\"width: 450px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eSpReaPa0HE1"
   },
   "source": [
    "## 1. Specify data -> write `dataspec.yml`\n",
    "\n",
    "BPNet takes as input nucleotide sequence and outputs the read coverage profile for multiple tracks at base-resolution. The coverage tracks can come from any genome-wide functional genomics assay that has a sufficient spatial resolution including ChIP-nexus, ChIP-exo, ChIP-seq, DNase-seq, and ATAC-seq. Additionally, different experiments may have differnet biases that need to be accounted for using the control or bias experiments. Both, the signal and the bias/control tracks have to be stored in [BigWig](https://genome.ucsc.edu/goldenpath/help/bigWig.html) files.\n",
    " \n",
    "\n",
    "The file paths to the BigWig tracks on which to train the model should be specified in a `dataspec.yml` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "id": "4LnaqSM_LM-M",
    "outputId": "aa784c6f-bc70-450d-db7e-3b5e5a677f8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fasta_file: ../data/mm10.subset.fa  # reference genome fasta file\r\n",
      "task_specs:  # specifies multiple tasks (e.g. Oct4, Sox2 Nanog)\r\n",
      "\r\n",
      "  Oct4:\r\n",
      "    tracks:\r\n",
      "      - ../data/chip-nexus/Oct4/counts.pos.subset.bw\r\n",
      "      - ../data/chip-nexus/Oct4/counts.neg.subset.bw\r\n",
      "    peaks: ../data/chip-nexus/Oct4/idr-optimal-set.summit.subset.bed.gz\r\n",
      "  Sox2:\r\n",
      "    tracks:\r\n",
      "      - ../data/chip-nexus/Sox2/counts.pos.subset.bw\r\n",
      "      - ../data/chip-nexus/Sox2/counts.neg.subset.bw\r\n",
      "    peaks: ../data/chip-nexus/Sox2/idr-optimal-set.summit.subset.bed.gz\r\n",
      "\r\n",
      "  Nanog: # Nanog is the task name\r\n",
      "    tracks:\r\n",
      "      # List of bigwig files (1 or more) corresponding to the task\r\n",
      "      # The model will predict each track individually (here coverage of\r\n",
      "      # reads mapping to the positive and negative strand) and\r\n",
      "      # the contribution scores will be averaged across all of these tracks\r\n",
      "      - ../data/chip-nexus/Nanog/counts.pos.subset.bw\r\n",
      "      - ../data/chip-nexus/Nanog/counts.neg.subset.bw\r\n",
      "\r\n",
      "    # Peaks associated with Nanog task (optional)\r\n",
      "    # These are used to later run TF-MoDISco for Nanog contrib scores\r\n",
      "    # only in the Nanog peaks.\r\n",
      "    peaks: ../data/chip-nexus/Nanog/idr-optimal-set.summit.subset.bed.gz\r\n",
      "\r\n",
      "bias_specs:  # specifies multiple bias tracks\r\n",
      "  input:  # first bias track\r\n",
      "    tracks:  # can specify multiple tracks\r\n",
      "      - ../data/chip-nexus/patchcap/counts.pos.subset.bw\r\n",
      "      - ../data/chip-nexus/patchcap/counts.neg.subset.bw\r\n",
      "    tasks:  # applies to Oct4, Sox2, Nanog tasks\r\n",
      "      - Oct4\r\n",
      "      - Sox2\r\n",
      "      - Nanog\r\n",
      "  # NOTE: bias_specs don't specify peaks since they are only used\r\n",
      "  # to correct for biases\r\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "exp_dir = Path('bpnet/examples/chip-nexus/') \n",
    "\n",
    "!cat {exp_dir}/dataspec.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YIOVdXQ9_M2q"
   },
   "source": [
    "### Data stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "iB2duLzl9LcR",
    "outputId": "c19db79d-1137-49e2-ef16-d06246d771c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr16\r\n",
      "chr17\r\n",
      "chr18\r\n",
      "chr19\r\n",
      "chr2\r\n"
     ]
    }
   ],
   "source": [
    "# chromsomome names of differnet peaks\n",
    "!zcat bpnet/examples/data/chip-nexus/*/idr-optimal-set.summit.subset.bed.gz | cut -f 1 | sort -u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ok51Hx8C9rJ2"
   },
   "source": [
    "Each task (or TF) can specify a set of peaks associated with it. Here are the number of peaks per TF we will use in this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "id": "WU5wXNcS-BNn",
    "outputId": "db69a716-852b-4f31-8fcd-75f59e36eda2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oct4\n",
      "5373\n",
      "Sox2\n",
      "2265\n",
      "Nanog\n",
      "12007\n"
     ]
    }
   ],
   "source": [
    "tasks = ['Oct4', 'Sox2', 'Nanog']\n",
    "\n",
    "# number of peaks per task\n",
    "for task in tasks:\n",
    "  print(task)\n",
    "  !zcat bpnet/examples/data/chip-nexus/{task}/idr-optimal-set.summit.subset.bed.gz | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IIWHUh4D-7yA"
   },
   "source": [
    "### FAQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vgRkcJy01dNF"
   },
   "source": [
    "#### How can I visualize the raw data before training the model?\n",
    "\n",
    "Glad you asked. Before you jump ahead and start training the model, we recommend eyeballing the coverage tracks (BigWig) and peak regions (bed) using the genome browser such as the [WashU](https://epigenomegateway.wustl.edu/) or [IGV](https://software.broadinstitute.org/software/igv/). If you can not identify peaks by eye then the model will not be able to do it either.\n",
    "\n",
    "Having specified your data in `dataspec.yml`, you can use also `bpnet.specs.DataSpec` to parse the file and visualize the tracks for a specific genomic interval in your jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J3Ck7qGJ1tSJ"
   },
   "source": [
    "#### How do I get my data into a BigWig file?\n",
    "\n",
    "Functional genomics experiments based on sequencing yield many short reads which then get aligned to the reference genome. The alignment locations of the reads are typically stored in the [BAM](http://samtools.github.io/hts-specs/SAMv1.pdf) file. There are different ways of computing the coverage tracks from aligned reads. To prevent loosing any spatial information in the profiles, we would like to generate non-smoothed tracks (as raw as possible). For ChIP-exo/nexus/seq experiments this means counting the 5' locations of the reads. Note that the aligned reads also have strand information hence you should generate two coverage tracks, one for the positive/forward and one for the negative/reverse strand. If multiple technical or biological replicate experiments were performed for a specific transcription factor, we recommend to add up their coverage (for example by merging the BAM files or adding the coverage tracks of the BigWig files).\n",
    "\n",
    "Here are the commands to do the conversion from BAM to BigWig for both strands:\n",
    "\n",
    "1. Sort the bam file: `samtools sort alignments.pos.bam alignments.sorted.bam`\n",
    "2. Convert BAM to bedGraph for positive and strand:\n",
    "```\n",
    "bedtools genomecov -5 -bg -strand + -ibam alignments.sorted.bam | sort -k1,1 -k2,2n > alignments.pos.bedGraph\n",
    "bedtools genomecov -5 -bg -strand - -ibam alignments.sorted.bam | sort -k1,1 -k2,2n > alignments.neg.bedGraph\n",
    "```\n",
    "3. Convert begGraph to bigwig using bedGraphToBigWig from UCSC ([download link](http://hgdownload.soe.ucsc.edu/admin/exe/linux.x86_64/bedGraphToBigWig)):\n",
    "```\n",
    "bedGraphToBigWig alignments.pos.bedGraph genome.chromosome-sizes.txt alignments.pos.bw\n",
    "bedGraphToBigWig alignments.neg.bedGraph genome.chromosome-sizes.txt alignments.neg.bw\n",
    "```\n",
    "\n",
    "`genome.chromosome-sizes.txt` is the genome file containing `chromosome_name<TAB>chromosome_length` entries.\n",
    "\n",
    "See also the [Snakemake rules](https://github.com/kundajelab/bpnet-manuscript/blob/d7af1bda3ac8cc342b32f9cdac481ba55fe7ddca/src/bpnet-pipeline/prepare-data.smk#L99-L133) for conversion from TagAlign files instead of BAM files and the [ChIP-nexus pipeline](https://github.com/kundajelab/chip-nexus-pipeline/blob/ea40683d65b9317843a7fbdcc75bd33e481bee8e/src/encode_count_signal_track.py#L29-L60).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WrX5_nHD11Ow"
   },
   "source": [
    "#### How do I get `regions.bed`?\n",
    "\n",
    "For large genomes such as human or mouse, training genome-wide can be computationally expensive. Most of the regions in the genome will contain very little counts, hence the model will not recieve a lot of information. We can significantly speed up the training process by training the model only in regions with higher number of counts. These regions are determined using traditional peak callers such as MACS2. Since we just want to discard regions with little or no counts, we don't care about the exact peak locations or even high false positive rates. Hence almost any peak caller should be fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8oDa0Ej13Tl"
   },
   "source": [
    "#### Can I train the model without the bias track?\n",
    "\n",
    "Technically, yes. It will work well for assays with low amount of bias such as ChIP-exo or ChIP-nexus. However, we generally recommend using the bias track. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XfyJoIOs16Fs"
   },
   "source": [
    "#### Can I train the model with differnet assays simultaneusly?\n",
    "\n",
    "Yes. If you are using different assays with similar resolution (e.g. ChIP-nexus and ChIP-exo), you can just specify the bigwig files and use different bias/control files for differnt subsets of the tracks. If you are using different assays with different resolutions, you might want to tweak the parameters of model output heads to best fit the individual experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7xrHLMWJ18Bg"
   },
   "source": [
    "#### Should I train a single multi-task model or multiple single-task models?\n",
    "\n",
    "If you expect the tracks to share some sequence motifs, it's likely beneficial to train a multi-task model (e.g. use a single `dataspec.yml`). Also, handling a single model is more convenient than handling multiple models. However, if you have many tracks it might be challenging to train a multi-task model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zphiFpBT1-5G"
   },
   "source": [
    "## 2. Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ojWuf4Jg1_pM"
   },
   "source": [
    "Having specified `dataspec.yml`, we are now ready to train the model with \n",
    "\n",
    "```\n",
    "bpnet train <dataspec.yml> <output dir> [optional flags]`\n",
    "```\n",
    "\n",
    "\n",
    "We will use a pre-made model [bpnet9](../bpnet/premade/bpnet9.gin) as a starting point and modify a few parameters specified in the config.gin file. Specifically, we will \n",
    "- train the model only on chromosomes 16-19\n",
    "- evaluate the model on chromosome 2\n",
    "- use only 3 layers of dilated convolutions \n",
    "- use an input sequence length of 200 bp and accordingly lower the augmentation shift to 100 bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "id": "3xFw1K-gLncD",
    "outputId": "884c5cbf-72b7-4bfc-c389-33d17ed9c07c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# exclude a large portion of the training set\r\n",
      "exclude_chr=[\"chrX\",\"chrY\",\"chr5\",\"chr6\",\"chr7\",\"chr10\",\"chr14\",\"chr11\",\"chr13\",\"chr12\",\"chr15\"]\r\n",
      "valid_chr = ['chr2']\r\n",
      "test_chr = ['chr1', 'chr8', 'chr9',\r\n",
      "            'chr3', 'chr4']\r\n",
      "seq_width = 200\r\n",
      "n_dil_layers = 3\r\n",
      "bpnet_data.interval_augmentation_shift = 100\r\n",
      "train.seed = 1"
     ]
    }
   ],
   "source": [
    "!cat {exp_dir}/config.gin\n",
    "# NOTE: test_chr will be also excluded similar to 'exclude_chr'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IR51oX6LAwW9"
   },
   "source": [
    "Have a look at the original gin file of bpnet9 here: https://github.com/kundajelab/bpnet/blob/master/bpnet/premade/bpnet9-ginspec.gin. For more information on using gin files see <https://github.com/google/gin-config>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FoTI8PJKLMZ9"
   },
   "source": [
    "To track model training and evaluation, we will use [wandb](http://wandb.com/) by adding `--wandb=avsec/bpnet-demo` to `bpnet train`. You can navigate to https://app.wandb.ai/avsec/bpnet-demo to see the training progress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcS0857OAIoy"
   },
   "source": [
    "Let's train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "PyaAb_VqCWt0"
   },
   "outputs": [],
   "source": [
    "# setup all the file paths\n",
    "model_dir = exp_dir / 'output'\n",
    "contrib_file = model_dir/'contrib.deeplift.h5'\n",
    "contrib_null_file = model_dir/'contrib.deeplift.null.h5'\n",
    "modisco_dir = model_dir/'modisco'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "yglTmu3FrtpB",
    "outputId": "234b17b8-0e5d-4dbe-aa7e-177ef15efad5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING:tensorflow:From /home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "2021-06-13 21:04:29,781 [WARNING] From /home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "2021-06-13 21:04:30,941 [INFO] Note: detected 112 virtual cores but NumExpr set to maximum of 64, check \"NUMEXPR_MAX_THREADS\" environment variable.\n",
      "2021-06-13 21:04:30,941 [INFO] Note: NumExpr detected 112 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2021-06-13 21:04:30,941 [INFO] NumExpr defaulting to 8 threads.\n",
      "Error.  nthreads cannot be larger than environment variable \"NUMEXPR_MAX_THREADS\" (64)/home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/bpnet-0.0.23-py3.6.egg/bpnet/plot/heatmaps.py:6: MatplotlibDeprecationWarning: \n",
      "The mpl_toolkits.axes_grid1.colorbar module was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use matplotlib.colorbar instead.\n",
      "  from mpl_toolkits.axes_grid1.colorbar import colorbar\n",
      "\u001b[32mINFO\u001b[0m \u001b[44m[06-13 21:04:32]\u001b[0m Using wandb. Running wandb.init()\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.9.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.10.32 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in run-20210613_210432-2021-06-13_21-04-25_60667d18-3bc0-48c1-ae7a-8fce4360ba26\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m2021-06-13_21-04-25_60667d18-3bc0-48c1-ae7a-8fce4360ba26\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://app.wandb.ai/avsec/bpnet-demo\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://app.wandb.ai/avsec/bpnet-demo/runs/2021-06-13_21-04-25_60667d18-3bc0-48c1-ae7a-8fce4360ba26\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
      "\n",
      "W&B Run: https://app.wandb.ai/avsec/bpnet-demo/runs/2021-06-13_21-04-25_60667d18-3bc0-48c1-ae7a-8fce4360ba26\n",
      "\u001b[32mINFO\u001b[0m \u001b[44m[06-13 21:04:38]\u001b[0m Using gpu: 0, memory fraction: 0.45\u001b[0m\n",
      "2021-06-13 21:04:38.229450: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2021-06-13 21:04:38.288371: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2700000000 Hz\n",
      "2021-06-13 21:04:38.300242: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56247e518010 executing computations on platform Host. Devices:\n",
      "2021-06-13 21:04:38.300304: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "\u001b[32mINFO\u001b[0m \u001b[44m[06-13 21:04:38]\u001b[0m Using the following premade configuration: bpnet9\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m \u001b[44m[06-13 21:04:38]\u001b[0m Using the following config.gin files: config.gin\u001b[0m\n",
      "TF-MoDISco is using the TensorFlow backend.\n",
      "*******************************************\n",
      "*******************************************\n",
      "*******************************************\n",
      "transformer working (200, 4)\n",
      "*******************************************\n",
      "*******************************************\n",
      "*******************************************\n",
      "(?, 200, 4)\n",
      "(?, 200, 4) (?, 200, 4) (?, 200, 4)\n",
      "QK.shape (?, 200, 200)\n",
      "(?, 200, 4) inp\n",
      "(?, ?, 2) (?, 200, 4)\n",
      "Used config: ----------------------------------------\n",
      "import bpnet\n",
      "import bpnet.configurables\n",
      "import bpnet.datasets\n",
      "import bpnet.heads\n",
      "import bpnet.layers\n",
      "import bpnet.losses\n",
      "import bpnet.metrics\n",
      "import bpnet.models\n",
      "import bpnet.seqmodel\n",
      "import bpnet.trainers\n",
      "\n",
      "# Macros:\n",
      "# ==============================================================================\n",
      "augment_interval = True\n",
      "batchnorm = False\n",
      "dataspec = 'dataspec.yml'\n",
      "exclude_chr = \\\n",
      "    ['chrX',\n",
      "     'chrY',\n",
      "     'chr5',\n",
      "     'chr6',\n",
      "     'chr7',\n",
      "     'chr10',\n",
      "     'chr14',\n",
      "     'chr11',\n",
      "     'chr13',\n",
      "     'chr12',\n",
      "     'chr15']\n",
      "filters = 64\n",
      "lambda = 10\n",
      "lr = 0.004\n",
      "n_bias_tracks = 2\n",
      "n_dil_layers = 3\n",
      "seq_width = 200\n",
      "tasks = ['Oct4', 'Sox2', 'Nanog']\n",
      "tconv_kernel_size = 25\n",
      "test_chr = ['chr1', 'chr8', 'chr9', 'chr3', 'chr4']\n",
      "tracks_per_task = 2\n",
      "use_bias = True\n",
      "valid_chr = ['chr2']\n",
      "\n",
      "# Parameters for Adam:\n",
      "# ==============================================================================\n",
      "Adam.amsgrad = False\n",
      "Adam.beta_1 = 0.9\n",
      "Adam.beta_2 = 0.999\n",
      "Adam.decay = 0.0\n",
      "Adam./home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/bpnet-0.0.23-py3.6.egg/bpnet/cli/train.py:195: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  gin_macro_dict = yaml.load(\"\\n\".join(macros).replace(\"@\", \"\").replace(\" = %\", \": \").replace(\" = \", \": \"))\n",
      "epsilon = None\n",
      "Adam.lr = %lr\n",
      "\n",
      "# Parameters for bpnet_data:\n",
      "# ==============================================================================\n",
      "bpnet_data.augment_interval = %augment_interval\n",
      "bpnet_data.dataspec = %dataspec\n",
      "bpnet_data.exclude_chr = %exclude_chr\n",
      "bpnet_data.include_metadata = False\n",
      "bpnet_data.interval_augmentation_shift = 100\n",
      "bpnet_data.intervals_file = None\n",
      "bpnet_data.intervals_format = 'bed'\n",
      "bpnet_data.peak_width = %seq_width\n",
      "bpnet_data.seq_width = %seq_width\n",
      "bpnet_data.shuffle = True\n",
      "bpnet_data.tasks = %tasks\n",
      "bpnet_data.test_chr = %test_chr\n",
      "bpnet_data.track_transform = None\n",
      "bpnet_data.valid_chr = %valid_chr\n",
      "\n",
      "# Parameters for ClassificationMetrics:\n",
      "# ==============================================================================\n",
      "# None.\n",
      "\n",
      "# Parameters for DeConv1D:\n",
      "# ==============================================================================\n",
      "DeConv1D.batchnorm = %batchnorm\n",
      "DeConv1D.filters = %filters\n",
      "DeConv1D.n_hidden = 0\n",
      "DeConv1D.n_tasks = %tracks_per_task\n",
      "DeConv1D.padding = 'same'\n",
      "DeConv1D.tconv_kernel_size = %tconv_kernel_size\n",
      "\n",
      "# Parameters for DilatedConv1D:\n",
      "# ==============================================================================\n",
      "DilatedConv1D.add_pointwise = False\n",
      "DilatedConv1D.batchnorm = %batchnorm\n",
      "DilatedConv1D.conv1_kernel_size = 25\n",
      "DilatedConv1D.filters = %filters\n",
      "DilatedConv1D.n_dil_layers = %n_dil_layers\n",
      "DilatedConv1D.padding = 'same'\n",
      "DilatedConv1D.skip_type = 'residual'\n",
      "\n",
      "# Parameters for GlobalAvgPoolFCN:\n",
      "# ==============================================================================\n",
      "GlobalAvgPoolFCN.batchnorm = %batchnorm\n",
      "GlobalAvgPoolFCN.dropout = 0\n",
      "GlobalAvgPoolFCN.dropout_hidden = 0\n",
      "GlobalAvgPoolFCN.hidden = None\n",
      "GlobalAvgPoolFCN.n_splines = 0\n",
      "GlobalAvgPoolFCN.n_tasks = %tracks_per_task\n",
      "\n",
      "# Parameters for IntervalAugmentor:\n",
      "# ==============================================================================\n",
      "# None.\n",
      "\n",
      "# Parameters for MetricsOrderedDict:\n",
      "# ==============================================================================\n",
      "# None.\n",
      "\n",
      "# Parameters for MovingAverages:\n",
      "# ==============================================================================\n",
      "MovingAverages.window_sizes = [1, 50]\n",
      "\n",
      "# Parameters for multinomial_nll:\n",
      "# ==============================================================================\n",
      "# None.\n",
      "\n",
      "# Parameters for PeakPredictionProfileMetric:\n",
      "# ==============================================================================\n",
      "PeakPredictionProfileMetric.binsizes = [1, 10]\n",
      "PeakPredictionProfileMetric.neg_max_threshold = 0.005\n",
      "PeakPredictionProfileMetric.pos_min_threshold = 0.015\n",
      "PeakPredictionProfileMetric.required_min_pos_counts = 2.5\n",
      "\n",
      "# Parameters for ProfileHead:\n",
      "# ==============================================================================\n",
      "ProfileHead.activation = None\n",
      "ProfileHead.bias_input = 'bias/{task}/profile'\n",
      "ProfileHead.bias_net = @MovingAverages()\n",
      "ProfileHead.bias_shape = (None, %n_bias_tracks)\n",
      "ProfileHead.loss = @multinomial_nll\n",
      "ProfileHead.loss_weight = 1\n",
      "ProfileHead.metric = @PeakPredictionProfileMetric()\n",
      "ProfileHead.net = @DeConv1D()\n",
      "ProfileHead.postproc_fn = @softmax\n",
      "ProfileHead.target_name = '{task}/profile'\n",
      "ProfileHead.use_bias = %use_bias\n",
      "\n",
      "# Parameters for RegressionMetrics:\n",
      "# ==============================================================================\n",
      "# None.\n",
      "\n",
      "# Parameters for report_template:\n",
      "# ==============================================================================\n",
      "report_template.name = 'evaluate.ipynb'\n",
      "report_template.raise_error = True\n",
      "\n",
      "# Parameters for ScalarHead:\n",
      "# ==============================================================================\n",
      "ScalarHead.activation = None\n",
      "ScalarHead.bias_input = 'bias/{task}/counts'\n",
      "ScalarHead.bias_net = None\n",
      "ScalarHead.bias_shape = (%n_bias_tracks,)\n",
      "ScalarHead.loss = 'mse'\n",
      "ScalarHead.loss_weight = %lambda\n",
      "ScalarHead.metric = @RegressionMetrics()\n",
      "ScalarHead.net = @GlobalAvgPoolFCN()\n",
      "ScalarHead.postproc_fn = None\n",
      "ScalarHead.target_name = '{task}/counts'\n",
      "ScalarHead.use_bias = %use_bias\n",
      "\n",
      "# Parameters for SeqModel:\n",
      "# ==============================================================================\n",
      "SeqModel.body = @DilatedConv1D()\n",
      "SeqModel.heads = [@ProfileHead(), @ScalarHead()]\n",
      "SeqModel.input_name = 'seq'\n",
      "SeqModel.input_shape = None\n",
      "SeqModel.optimizer = @keras.optimizers.Adam()\n",
      "SeqModel.seqlen = %seq_width\n",
      "SeqModel.tasks = %tasks\n",
      "\n",
      "# Parameters for StrandedProfile:\n",
      "# ==============================================================================\n",
      "StrandedProfile.excl_chromosomes = None\n",
      "StrandedProfile.include_classes = False\n",
      "\n",
      "# Parameters for train:\n",
      "# ==============================================================================\n",
      "train.batch_size = 128\n",
      "train.data = @bpnet_data()\n",
      "train.early_stop_patience = 5\n",
      "train.epochs = 10\n",
      "train.eval_metric = None\n",
      "train.eval_report = @report_template()\n",
      "train.eval_skip = []\n",
      "train.eval_train = False\n",
      "train.model = @SeqModel()\n",
      "train.seed = 1\n",
      "train.stratified_sampler_p = None\n",
      "train.tensorboard = True\n",
      "train.train_batch_sampler = None\n",
      "train.train_epoch_frac = 1.0\n",
      "train.train_samples_per_epoch = None\n",
      "train.valid_epoch_frac = 1.0\n",
      "train.validation_samples = None\n",
      "\n",
      "----------------------------------------------------\n",
      "/home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/bpnet-0.0.23-py3.6.egg/bpnet/cli/train.py:208: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  .replace(\" = \", \": \"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m \u001b[44m[06-13 21:04:42]\u001b[0m Loading the training data into memory\u001b[0m\n",
      "100%|███████████████████████████████████████████| 99/99 [00:03<00:00, 27.78it/s]\n",
      "\u001b[32mINFO\u001b[0m \u001b[44m[06-13 21:04:46]\u001b[0m Loading the validation data into memory\u001b[0m\n",
      "100%|███████████████████████████████████████████| 56/56 [00:02<00:00, 22.14it/s]\n",
      "100%|███████████████████████████████████████████| 99/99 [00:04<00:00, 24.46it/s]\n",
      "2021-06-13 21:04:54.941854: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "Epoch 1/10\n",
      "98/98 [==============================] - 14s 141ms/step - loss: 1071.9160 - Oct4/profile_loss: 275.0354 - Oct4/counts_loss: 3.2327 - Sox2/profile_loss: 143.4014 - Sox2/counts_loss: 1.2697 - Nanog/profile_loss: 590.6003 - Nanog/counts_loss: 1.7856 - val_loss: 969.8797 - val_Oct4/profile_loss: 265.9058 - val_Oct4/counts_loss: 1.6072 - val_Sox2/profile_loss: 142.3126 - val_Sox2/counts_loss: 0.9467 - val_Nanog/profile_loss: 523.9103 - val_Nanog/counts_loss: 1.2212\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 12s 126ms/step - loss: 912.8407 - Oct4/profile_loss: 250.9383 - Oct4/counts_loss: 1.6473 - Sox2/profile_loss: 140.6293 - Sox2/counts_loss: 0.9302 - Nanog/profile_loss: 483.3309 - Nanog/counts_loss: 1.2167 - val_loss: 894.4459 - val_Oct4/profile_loss: 252.9329 - val_Oct4/counts_loss: 1.4208 - val_Sox2/profile_loss: 141.9273 - val_Sox2/counts_loss: 0.8661 - val_Nanog/profile_loss: 464.6298 - val_Nanog/counts_loss: 1.2087\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 13s 131ms/step - loss: 858.6909 - Oct4/profile_loss: 243.7244 - Oct4/counts_loss: 1.4922 - Sox2/profile_loss: 139.4453 - Sox2/counts_loss: 0.8534 - Nanog/profile_loss: 439.7242 - Nanog/counts_loss: 1.2342 - val_loss: 862.8011 - val_Oct4/profile_loss: 247.8206 - val_Oct4/counts_loss: 1.5134 - val_Sox2/profile_loss: 140.5145 - val_Sox2/counts_loss: 0.8068 - val_Nanog/profile_loss: 438.9541 - val_Nanog/counts_loss: 1.2310\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 12s 125ms/step - loss: 832.4283 - Oct4/profile_loss: 240.3951 - Oct4/counts_loss: 1.2767 - Sox2/profile_loss: 138.2264 - Sox2/counts_loss: 0.7870 - Nanog/profile_loss: 421.2717 - Nanog/counts_loss: 1.1899 - val_loss: 841.9460 - val_Oct4/profile_loss: 243.8964 - val_Oct4/counts_loss: 1.1194 - val_Sox2/profile_loss: 138.8500 - val_Sox2/counts_loss: 0.7297 - val_Nanog/profile_loss: 429.2572 - val_Nanog/counts_loss: 1.1451\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 13s 132ms/step - loss: 817.7956 - Oct4/profile_loss: 237.9665 - Oct4/counts_loss: 1.1009 - Sox2/profile_loss: 136.6305 - Sox2/counts_loss: 0.7334 - Nanog/profile_loss: 413.2811 - Nanog/counts_loss: 1.1574 - val_loss: 835.4901 - val_Oct4/profile_loss: 242.3055 - val_Oct4/counts_loss: 1.0117 - val_Sox2/profile_loss: 138.3665 - val_Sox2/counts_loss: 0.6902 - val_Nanog/profile_loss: 426.7596 - val_Nanog/counts_loss: 1.1039\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 12s 126ms/step - loss: 815.2564 - Oct4/profile_loss: 237.6115 - Oct4/counts_loss: 0.9959 - Sox2/profile_loss: 136.4318 - Sox2/counts_loss: 0.7064 - Nanog/profile_loss: 412.8075 - Nanog/counts_loss: 1.1382 - val_loss: 832.4509 - val_Oct4/profile_loss: 242.9575 - val_Oct4/counts_loss: 0.9295 - val_Sox2/profile_loss: 137.9686 - val_Sox2/counts_loss: 0.6696 - val_Nanog/profile_loss: 424.5338 - val_Nanog/counts_loss: 1.1000\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - ETA: 0s - loss: 803.8164 - Oct4/profile_loss: 235.8158 - Oct4/counts_loss: 0.9055 - Sox2/profile_loss: 135.0492 - Sox2/counts_loss: 0.6714 - Nanog/profile_loss: 406.1050 - Nanog/counts_loss: 1.10 - 12s 127ms/step - loss: 804.0822 - Oct4/profile_loss: 235.9544 - Oct4/counts_loss: 0.9064 - Sox2/profile_loss: 135.1294 - Sox2/counts_loss: 0.6730 - Nanog/profile_loss: 406.1113 - Nanog/counts_loss: 1.1093 - val_loss: 825.9868 - val_Oct4/profile_loss: 242.1129 - val_Oct4/counts_loss: 0.8478 - val_Sox2/profile_loss: 137.0896 - val_Sox2/counts_loss: 0.6398 - val_Nanog/profile_loss: 420.9803 - val_Nanog/counts_loss: 1.0928\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 12s 126ms/step - loss: 809.4759 - Oct4/profile_loss: 236.9713 - Oct4/counts_loss: 0.8456 - Sox2/profile_loss: 135.6250 - Sox2/counts_loss: 0.6689 - Nanog/profile_loss: 410.4409 - Nanog/counts_loss: 1.1294 - val_loss: 831.3736 - val_Oct4/profile_loss: 243.9704 - val_Oct4/counts_loss: 0.7991 - val_Sox2/profile_loss: 138.0169 - val_Sox2/counts_loss: 0.6313 - val_Nanog/profile_loss: 424.1953 - val_Nanog/counts_loss: 1.0887ss: 0.6782 - Nanog/profile_loss: 414.\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 12s 121ms/step - loss: 802.9669 - Oct4/profile_loss: 237.0705 - Oct4/counts_loss: 0.8144 - Sox2/profile_loss: 135.3097 - Sox2/counts_loss: 0.6538 - Nanog/profile_loss: 404.8933 - Nanog/counts_loss: 1.1011 - val_loss: 824.8850 - val_Oct4/profile_loss: 242.5287 - val_Oct4/counts_loss: 0.8228 - val_Sox2/profile_loss: 137.0316 - val_Sox2/counts_loss: 0.6524 - val_Nanog/profile_loss: 419.0970 - val_Nanog/counts_loss: 1.1475\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 13s 130ms/step - loss: 798.0629 - Oct4/profile_loss: 236.5533 - Oct4/counts_loss: 0.7638 - Sox2/profile_loss: 135.0245 - Sox2/counts_loss: 0.6350 - Nanog/profile_loss: 401.6114 - Nanog/counts_loss: 1.0886 - val_loss: 822.1075 - val_Oct4/profile_loss: 240.4559 - val_Oct4/counts_loss: 0.8298 - val_Sox2/profile_loss: 135.9702 - val_Sox2/counts_loss: 0.6379 - val_Nanog/profile_loss: 419.8187 - val_Nanog/counts_loss: 1.1186\n",
      "\u001b[32mINFO\u001b[0m \u001b[44m[06-13 21:07:02]\u001b[0m Evaluating dataset: valid-peaks\u001b[0m\n",
      "56it [00:03, 16.77it/s]                                                         \n",
      "/home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/bpnet-0.0.23-py3.6.egg/bpnet/metrics.py:108: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fracs = yt / yt.sum(axis=1, keepdims=True)\n",
      "\u001b[32mINFO\u001b[0m \u001b[44m[06-13 21:07:07]\u001b[0m Evaluating dataset: train-peaks\u001b[0m\n",
      "99it [00:05, 17.63it/s]                                                         \n",
      "\u001b[32mINFO\u001b[0m \u001b[44m[06-13 21:07:14]\u001b[0m Saved metrics to ./2021-06-13_21-04-25_60667d18-3bc0-48c1-ae7a-8fce4360ba26/evaluation.valid.json\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m \u001b[44m[06-13 21:07:14]\u001b[0m Done!\u001b[0m\n",
      "----------------------------------------\n",
      "Final metrics: \n",
      "{\n",
      "  \"valid-peaks\": {\n",
      "    \"Oct4/profile/binsize=1/auprc\": 0.5805770034388952,\n",
      "    \"Oct4/profile/binsize=1/random_auprc\": 0.10536452404225709,\n",
      "    \"Oct4/profile/binsize=1/n_positives\": 17576,\n",
      "    \"Oct4/profile/binsize=1/frac_ambigous\": 0.3000041876046901,\n",
      "    \"Oct4/profile/binsize=1/imbalance\": 0.10514540048696151,\n",
      "    \"Oct4/profile/binsize=10/auprc\": 0.9433049257077277,\n",
      "    \"Oct4/profile/binsize=10/random_auprc\": 0.7759771503001796,\n",
      "    \"Oct4/profile/binsize=10/n_positives\": 9129,\n",
      "    \"Oct4/profile/binsize=10/frac_ambigous\": 0.5101340033500837,\n",
      "    \"Oct4/profile/binsize=10/imbalance\": 0.7803898102239699,\n",
      "    \"Oct4/counts/mse\": 0.8319705724716187,\n",
      "    \"Oct4/counts/var_explained\": 0.08711695671081543,\n",
      "    \"Oct4/counts/pearsonr\": 0.34355979263065334,\n",
      "    \"Oct4/counts/spearmanr\": 0.3153760998145383,\n",
      "    \"Oct4/counts/mad\": 0.7344832420349121,\n",
      "    \"Sox2/profile/binsize=1/auprc\": 0.5919803179355589,\n",
      "    \"Sox2/profile/binsize=1/random_auprc\": 0.10879881083267622,\n",
      "    \"Sox2/profile/binsize=1/n_positives\": 3699,\n",
      "    \"Sox2/profile/binsize=1/frac_ambigous\": 0.26811440677966103,\n",
      "    \"Sox2/profile/binsize=1/imbalance\": 0.10707772470690403,\n",
      "    \"Sox2/profile/binsize=10/auprc\": 0.9441912773678758,\n",
      "    \"Sox2/profile/binsize=10/random_auprc\": 0.7431602869134067,\n",
      "    \"Sox2/profile/binsize=10/n_positives\": 1779,\n",
      "    \"Sox2/profile/binsize=10/frac_ambigous\": 0.4864406779661017,\n",
      "    \"Sox2/profile/binsize=10/imbalance\": 0.7339108910891089,\n",
      "    \"Sox2/counts/mse\": 0.6502151489257812,\n",
      "    \"Sox2/counts/var_explained\": 0.0862531065940857,\n",
      "    \"Sox2/counts/pearsonr\": 0.36199269261264533,\n",
      "    \"Sox2/counts/spearmanr\": 0.3506800526944667,\n",
      "    \"Sox2/counts/mad\": 0.6565879583358765,\n",
      "    \"Nanog/profile/binsize=1/auprc\": 0.5859119403432145,\n",
      "    \"Nanog/profile/binsize=1/random_auprc\": 0.0982463910867325,\n",
      "    \"Nanog/profile/binsize=1/n_positives\": 57470,\n",
      "    \"Nanog/profile/binsize=1/frac_ambigous\": 0.27505718547986074,\n",
      "    \"Nanog/profile/binsize=1/imbalance\": 0.09855198715926083,\n",
      "    \"Nanog/profile/binsize=10/auprc\": 0.8997501954872384,\n",
      "    \"Nanog/profile/binsize=10/random_auprc\": 0.6247912670442766,\n",
      "    \"Nanog/profile/binsize=10/n_positives\": 25123,\n",
      "    \"Nanog/profile/binsize=10/frac_ambigous\": 0.5016036797613128,\n",
      "    \"Nanog/profile/binsize=10/imbalance\": 0.6266493726771595,\n",
      "    \"Nanog/counts/mse\": 1.1316605806350708,\n",
      "    \"Nanog/counts/var_explained\": 0.12737709283828735,\n",
      "    \"Nanog/counts/pearsonr\": 0.3727536560231944,\n",
      "    \"Nanog/counts/spearmanr\": 0.35026001617462593,\n",
      "    \"Nanog/counts/mad\": 0.8763851523399353,\n",
      "    \"avg/profile/binsize=1/auprc\": 0.5861564205725561,\n",
      "    \"avg/profile/binsize=1/random_auprc\": 0.10413657532055527,\n",
      "    \"avg/profile/binsize=1/n_positives\": 26248.333333333332,\n",
      "    \"avg/profile/binsize=1/frac_ambigous\": 0.28105859328807065,\n",
      "    \"avg/profile/binsize=1/imbalance\": 0.1035917041177088,\n",
      "    \"avg/profile/binsize=10/auprc\": 0.9290821328542807,\n",
      "    \"avg/profile/binsize=10/random_auprc\": 0.7146429014192877,\n",
      "    \"avg/profile/binsize=10/n_positives\": 12010.333333333334,\n",
      "    \"avg/profile/binsize=10/frac_ambigous\": 0.4993927870258328,\n",
      "    \"avg/profile/binsize=10/imbalance\": 0.7136500246634127,\n",
      "    \"avg/counts/mse\": 0.8712821006774902,\n",
      "    \"avg/counts/var_explained\": 0.10024905204772949,\n",
      "    \"avg/counts/pearsonr\": 0.35943538042216433,\n",
      "    \"avg/counts/spearmanr\": 0.3387720562278769,\n",
      "    \"avg/counts/mad\": 0.755818784236908\n",
      "  },\n",
      "  \"train-peaks\": {\n",
      "    \"Oct4/profile/binsize=1/auprc\": 0.6021819679111583,\n",
      "    \"Oct4/profile/binsize=1/random_auprc\": 0.1090942526242791,\n",
      "    \"Oct4/profile/binsize=1/n_positives\": 30625,\n",
      "    \"Oct4/profile/binsize=1/frac_ambigous\": 0.29469681908548706,\n",
      "    \"Oct4/profile/binsize=1/imbalance\": 0.10790517733445143,\n",
      "    \"Oct4/profile/binsize=10/auprc\": 0.946456019841667,\n",
      "    \"Oct4/profile/binsize=10/random_auprc\": 0.776684594893082,\n",
      "    \"Oct4/profile/binsize=10/n_positives\": 15747,\n",
      "    \"Oct4/profile/binsize=10/frac_ambigous\": 0.49358846918489063,\n",
      "    \"Oct4/profile/binsize=10/imbalance\": 0.7727451172833448,\n",
      "    \"Oct4/counts/mse\": 0.8595675826072693,\n",
      "    \"Oct4/counts/var_explained\": 0.07855808734893799,\n",
      "    \"Oct4/counts/pearsonr\": 0.3099009113916154,\n",
      "    \"Oct4/counts/spearmanr\": 0.2873417612340714,\n",
      "    \"Oct4/counts/mad\": 0.7519600987434387,\n",
      "    \"Sox2/profile/binsize=1/auprc\": 0.6687051671525351,\n",
      "    \"Sox2/profile/binsize=1/random_auprc\": 0.10865745143248316,\n",
      "    \"Sox2/profile/binsize=1/n_positives\": 5603,\n",
      "    \"Sox2/profile/binsize=1/frac_ambigous\": 0.2707022471910112,\n",
      "    \"Sox2/profile/binsize=1/imbalance\": 0.1079035550591226,\n",
      "    \"Sox2/profile/binsize=10/auprc\": 0.9499068413718156,\n",
      "    \"Sox2/profile/binsize=10/random_auprc\": 0.7215290630981378,\n",
      "    \"Sox2/profile/binsize=10/n_positives\": 2623,\n",
      "    \"Sox2/profile/binsize=10/frac_ambigous\": 0.4872191011235955,\n",
      "    \"Sox2/profile/binsize=10/imbalance\": 0.7184333059435771,\n",
      "    \"Sox2/counts/mse\": 0.6751421093940735,\n",
      "    \"Sox2/counts/var_explained\": 0.0824962854385376,\n",
      "    \"Sox2/counts/pearsonr\": 0.35352961544031347,\n",
      "    \"Sox2/counts/spearmanr\": 0.3371034925703734,\n",
      "    \"Sox2/counts/mad\": 0.6665996313095093,\n",
      "    \"Nanog/profile/binsize=1/auprc\": 0.6175686334240247,\n",
      "    \"Nanog/profile/binsize=1/random_auprc\": 0.09805910353418598,\n",
      "    \"Nanog/profile/binsize=1/n_positives\": 101187,\n",
      "    \"Nanog/profile/binsize=1/frac_ambigous\": 0.2719046267385751,\n",
      "    \"Nanog/profile/binsize=1/imbalance\": 0.09861973115848238,\n",
      "    \"Nanog/profile/binsize=10/auprc\": 0.9107511134763839,\n",
      "    \"Nanog/profile/binsize=10/random_auprc\": 0.6207859932685165,\n",
      "    \"Nanog/profile/binsize=10/n_positives\": 43972,\n",
      "    \"Nanog/profile/binsize=10/frac_ambigous\": 0.4973389156968493,\n",
      "    \"Nanog/profile/binsize=10/imbalance\": 0.6207665701983482,\n",
      "    \"Nanog/counts/mse\": 1.1610476970672607,\n",
      "    \"Nanog/counts/var_explained\": 0.12104427814483643,\n",
      "    \"Nanog/counts/pearsonr\": 0.3620179513612261,\n",
      "    \"Nanog/counts/spearmanr\": 0.3385852849092467,\n",
      "    \"Nanog/counts/mad\": 0.8907265663146973,\n",
      "    \"avg/profile/binsize=1/auprc\": 0.6294852561625727,\n",
      "    \"avg/profile/binsize=1/random_auprc\": 0.10527026919698275,\n",
      "    \"avg/profile/binsize=1/n_positives\": 45805.0,\n",
      "    \"avg/profile/binsize=1/frac_ambigous\": 0.27910123100502443,\n",
      "    \"avg/profile/binsize=1/imbalance\": 0.10480948785068546,\n",
      "    \"avg/profile/binsize=10/auprc\": 0.9357046582299556,\n",
      "    \"avg/profile/binsize=10/random_auprc\": 0.7063332170865788,\n",
      "    \"avg/profile/binsize=10/n_positives\": 20780.666666666668,\n",
      "    \"avg/profile/binsize=10/frac_ambigous\": 0.49271549533511183,\n",
      "    \"avg/profile/binsize=10/imbalance\": 0.7039816644750901,\n",
      "    \"avg/counts/mse\": 0.8985857963562012,\n",
      "    \"avg/counts/var_explained\": 0.094032883644104,\n",
      "    \"avg/counts/pearsonr\": 0.3418161593977183,\n",
      "    \"avg/counts/spearmanr\": 0.3210101795712305,\n",
      "    \"avg/counts/mad\": 0.7697620987892151\n",
      "  }\n",
      "}\n",
      "\u001b[32mINFO\u001b[0m \u001b[44m[06-13 21:07:14]\u001b[0m Running the evaluation report\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing:  10%|███▏                           | 3/29 [00:04<00:37,  1.43s/cell]2021-06-13 21:07:20.305316: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2021-06-13 21:07:20.326385: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2700000000 Hz\n",
      "2021-06-13 21:07:20.328321: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a284665a40 executing computations on platform Host. Devices:\n",
      "2021-06-13 21:07:20.328369: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "Executing:  21%|██████▍                        | 6/29 [00:05<00:23,  1.02s/cell]Error.  nthreads cannot be larger than environment variable \"NUMEXPR_MAX_THREADS\" (64)2021-06-13 21:07:23.527728: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "Executing: 100%|██████████████████████████████| 29/29 [00:32<00:00,  1.12s/cell]\n",
      "[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.\n",
      "[NbConvertApp] Converting notebook evaluate.ipynb to html\n",
      "[NbConvertApp] Writing 2267132 bytes to evaluate.html\n",
      "\u001b[32mINFO\u001b[0m \u001b[44m[06-13 21:07:50]\u001b[0m Done training and evaluating the model. Model and metrics can be found in: ./2021-06-13_21-04-25_60667d18-3bc0-48c1-ae7a-8fce4360ba26\u001b[0m\n",
      "OrderedDict([('valid-peaks', {'Oct4/profile/binsize=1/auprc': 0.5805770034388952, 'Oct4/profile/binsize=1/random_auprc': 0.10536452404225709, 'Oct4/profile/binsize=1/n_positives': 17576, 'Oct4/profile/binsize=1/frac_ambigous': 0.3000041876046901, 'Oct4/profile/binsize=1/imbalance': 0.10514540048696151, 'Oct4/profile/binsize=10/auprc': 0.9433049257077277, 'Oct4/profile/binsize=10/random_auprc': 0.7759771503001796, 'Oct4/profile/binsize=10/n_positives': 9129, 'Oct4/profile/binsize=10/frac_ambigous': 0.5101340033500837, 'Oct4/profile/binsize=10/imbalance': 0.7803898102239699, 'Oct4/counts/mse': 0.8319706, 'Oct4/counts/var_explained': 0.08711695671081543, 'Oct4/counts/pearsonr': 0.34355979263065334, 'Oct4/counts/spearmanr': 0.3153760998145383, 'Oct4/counts/mad': 0.73448324, 'Sox2/profile/binsize=1/auprc': 0.5919803179355589, 'Sox2/profile/binsize=1/random_auprc': 0.10879881083267622, 'Sox2/profile/binsize=1/n_positives': 3699, 'Sox2/profile/binsize=1/frac_ambigous': 0.26811440677966103, 'Sox2/profile/binsize=1/imbalance': 0.10707772470690403, 'Sox2/profile/binsize=10/auprc': 0.9441912773678758, 'Sox2/profile/binsize=10/random_auprc': 0.7431602869134067, 'Sox2/profile/binsize=10/n_positives': 1779, 'Sox2/profile/binsize=10/frac_ambigous': 0.4864406779661017, 'Sox2/profile/binsize=10/imbalance': 0.7339108910891089, 'Sox2/counts/mse': 0.65021515, 'Sox2/counts/var_explained': 0.0862531065940857, 'Sox2/counts/pearsonr': 0.36199269261264533, 'Sox2/counts/spearmanr': 0.3506800526944667, 'Sox2/counts/mad': 0.65658796, 'Nanog/profile/binsize=1/auprc': 0.5859119403432145, 'Nanog/profile/binsize=1/random_auprc': 0.0982463910867325, 'Nanog/profile/binsize=1/n_positives': 57470, 'Nanog/profile/binsize=1/frac_ambigous': 0.27505718547986074, 'Nanog/profile/binsize=1/imbalance': 0.09855198715926083, 'Nanog/profile/binsize=10/auprc': 0.8997501954872384, 'Nanog/profile/binsize=10/random_auprc': 0.6247912670442766, 'Nanog/profile/binsize=10/n_positives': 25123, 'Nanog/profile/binsize=10/frac_ambigous': 0.5016036797613128, 'Nanog/profile/binsize=10/imbalance': 0.6266493726771595, 'Nanog/counts/mse': 1.1316606, 'Nanog/counts/var_explained': 0.12737709283828735, 'Nanog/counts/pearsonr': 0.3727536560231944, 'Nanog/counts/spearmanr': 0.35026001617462593, 'Nanog/counts/mad': 0.87638515, 'avg/profile/binsize=1/auprc': 0.5861564205725561, 'avg/profile/binsize=1/random_auprc': 0.10413657532055527, 'avg/profile/binsize=1/n_positives': 26248.333333333332, 'avg/profile/binsize=1/frac_ambigous': 0.28105859328807065, 'avg/profile/binsize=1/imbalance': 0.1035917041177088, 'avg/profile/binsize=10/auprc': 0.9290821328542807, 'avg/profile/binsize=10/random_auprc': 0.7146429014192877, 'avg/profile/binsize=10/n_positives': 12010.333333333334, 'avg/profile/binsize=10/frac_ambigous': 0.4993927870258328, 'avg/profile/binsize=10/imbalance': 0.7136500246634127, 'avg/counts/mse': 0.8712821006774902, 'avg/counts/var_explained': 0.10024905204772949, 'avg/counts/pearsonr': 0.35943538042216433, 'avg/counts/spearmanr': 0.3387720562278769, 'avg/counts/mad': 0.755818784236908}), ('train-peaks', {'Oct4/profile/binsize=1/auprc': 0.6021819679111583, 'Oct4/profile/binsize=1/random_auprc': 0.1090942526242791, 'Oct4/profile/binsize=1/n_positives': 30625, 'Oct4/profile/binsize=1/frac_ambigous': 0.29469681908548706, 'Oct4/profile/binsize=1/imbalance': 0.10790517733445143, 'Oct4/profile/binsize=10/auprc': 0.946456019841667, 'Oct4/profile/binsize=10/random_auprc': 0.776684594893082, 'Oct4/profile/binsize=10/n_positives': 15747, 'Oct4/profile/binsize=10/frac_ambigous': 0.49358846918489063, 'Oct4/profile/binsize=10/imbalance': 0.7727451172833448, 'Oct4/counts/mse': 0.8595676, 'Oct4/counts/var_explained': 0.07855808734893799, 'Oct4/counts/pearsonr': 0.3099009113916154, 'Oct4/counts/spearmanr': 0.2873417612340714, 'Oct4/counts/mad': 0.7519601, 'Sox2/profile/binsize=1/auprc': 0.6687051671525351, 'Sox2/profile/binsize=1/random_auprc': 0.10865745143248316, 'Sox2/profile/binsize=1/n_positives': 5603, 'Sox2/profile/binsize=1/frac_ambigous': 0.2707022471910112, 'Sox2/profile/binsize=1/imbalance': 0.1079035550591226, 'Sox2/profile/binsize=10/auprc': 0.9499068413718156, 'Sox2/profile/binsize=10/random_auprc': 0.7215290630981378, 'Sox2/profile/binsize=10/n_positives': 2623, 'Sox2/profile/binsize=10/frac_ambigous': 0.4872191011235955, 'Sox2/profile/binsize=10/imbalance': 0.7184333059435771, 'Sox2/counts/mse': 0.6751421, 'Sox2/counts/var_explained': 0.0824962854385376, 'Sox2/counts/pearsonr': 0.35352961544031347, 'Sox2/counts/spearmanr': 0.3371034925703734, 'Sox2/counts/mad': 0.66659963, 'Nanog/profile/binsize=1/auprc': 0.6175686334240247, 'Nanog/profile/binsize=1/random_auprc': 0.09805910353418598, 'Nanog/profile/binsize=1/n_positives': 101187, 'Nanog/profile/binsize=1/frac_ambigous': 0.2719046267385751, 'Nanog/profile/binsize=1/imbalance': 0.09861973115848238, 'Nanog/profile/binsize=10/auprc': 0.9107511134763839, 'Nanog/profile/binsize=10/random_auprc': 0.6207859932685165, 'Nanog/profile/binsize=10/n_positives': 43972, 'Nanog/profile/binsize=10/frac_ambigous': 0.4973389156968493, 'Nanog/profile/binsize=10/imbalance': 0.6207665701983482, 'Nanog/counts/mse': 1.1610477, 'Nanog/counts/var_explained': 0.12104427814483643, 'Nanog/counts/pearsonr': 0.3620179513612261, 'Nanog/counts/spearmanr': 0.3385852849092467, 'Nanog/counts/mad': 0.89072657, 'avg/profile/binsize=1/auprc': 0.6294852561625727, 'avg/profile/binsize=1/random_auprc': 0.10527026919698275, 'avg/profile/binsize=1/n_positives': 45805.0, 'avg/profile/binsize=1/frac_ambigous': 0.27910123100502443, 'avg/profile/binsize=1/imbalance': 0.10480948785068546, 'avg/profile/binsize=10/auprc': 0.9357046582299556, 'avg/profile/binsize=10/random_auprc': 0.7063332170865788, 'avg/profile/binsize=10/n_positives': 20780.666666666668, 'avg/profile/binsize=10/frac_ambigous': 0.49271549533511183, 'avg/profile/binsize=10/imbalance': 0.7039816644750901, 'avg/counts/mse': 0.8985857963562012, 'avg/counts/var_explained': 0.094032883644104, 'avg/counts/pearsonr': 0.3418161593977183, 'avg/counts/spearmanr': 0.3210101795712305, 'avg/counts/mad': 0.7697620987892151})])\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 82340\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                  val_loss 822.1075197582511\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                  _runtime 150.7436351776123\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                          Sox2/counts_loss 0.6335170552771152\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                     val_Sox2/profile_loss 135.97024292634478\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                          Oct4/counts_loss 0.762623556511141\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                      val_Oct4/counts_loss 0.8297812440853496\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                        Nanog/profile_loss 401.21186416385797\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                         Nanog/counts_loss 1.0861293434369155\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                _timestamp 1623589621.4792895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                     _step 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                      loss 797.3432320344498\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                    val_Nanog/profile_loss 419.8187214726413\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                     epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                     val_Nanog/counts_loss 1.1185805176870613\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                     val_Oct4/profile_loss 240.45589009186403\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                         Oct4/profile_loss 236.38531764710865\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                      val_Sox2/counts_loss 0.637904399080924\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                         Sox2/profile_loss 134.9233503724615\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                             best_val_loss 822.1075197582511\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                best_epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                          best-epoch/epoch 9.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                              best-epoch/Nanog/counts_loss 1.0861293434369157\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                             best-epoch/Nanog/profile_loss 401.211864163858\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               best-epoch/Oct4/counts_loss 0.7626235565111411\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                              best-epoch/Oct4/profile_loss 236.38531764710862\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               best-epoch/Sox2/counts_loss 0.6335170552771152\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                              best-epoch/Sox2/profile_loss 134.9233503724615\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                           best-epoch/loss 797.3432320344498\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          best-epoch/val_Nanog/counts_loss 1.1185805176870611\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                         best-epoch/val_Nanog/profile_loss 419.8187214726413\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                           best-epoch/val_Oct4/counts_loss 0.8297812440853496\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          best-epoch/val_Oct4/profile_loss 240.455890091864\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                           best-epoch/val_Sox2/counts_loss 0.6379043990809239\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          best-epoch/val_Sox2/profile_loss 135.97024292634478\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                       best-epoch/val_loss 822.1075197582512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             eval/valid-peaks/Oct4/profile/binsize=1/auprc 0.5805770034388952\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      eval/valid-peaks/Oct4/profile/binsize=1/random_auprc 0.10536452404225709\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       eval/valid-peaks/Oct4/profile/binsize=1/n_positives 17576\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     eval/valid-peaks/Oct4/profile/binsize=1/frac_ambigous 0.3000041876046901\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         eval/valid-peaks/Oct4/profile/binsize=1/imbalance 0.10514540048696151\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            eval/valid-peaks/Oct4/profile/binsize=10/auprc 0.9433049257077277\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     eval/valid-peaks/Oct4/profile/binsize=10/random_auprc 0.7759771503001796\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      eval/valid-peaks/Oct4/profile/binsize=10/n_positives 9129\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    eval/valid-peaks/Oct4/profile/binsize=10/frac_ambigous 0.5101340033500837\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/valid-peaks/Oct4/profile/binsize=10/imbalance 0.7803898102239699\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          eval/valid-peaks/Oct4/counts/mse 0.8319705724716187\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                eval/valid-peaks/Oct4/counts/var_explained 0.08711695671081543\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     eval/valid-peaks/Oct4/counts/pearsonr 0.34355979263065334\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                    eval/valid-peaks/Oct4/counts/spearmanr 0.3153760998145383\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          eval/valid-peaks/Oct4/counts/mad 0.7344832420349121\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             eval/valid-peaks/Sox2/profile/binsize=1/auprc 0.5919803179355589\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      eval/valid-peaks/Sox2/profile/binsize=1/random_auprc 0.10879881083267622\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       eval/valid-peaks/Sox2/profile/binsize=1/n_positives 3699\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     eval/valid-peaks/Sox2/profile/binsize=1/frac_ambigous 0.26811440677966103\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         eval/valid-peaks/Sox2/profile/binsize=1/imbalance 0.10707772470690403\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            eval/valid-peaks/Sox2/profile/binsize=10/auprc 0.9441912773678758\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     eval/valid-peaks/Sox2/profile/binsize=10/random_auprc 0.7431602869134067\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      eval/valid-peaks/Sox2/profile/binsize=10/n_positives 1779\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    eval/valid-peaks/Sox2/profile/binsize=10/frac_ambigous 0.4864406779661017\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/valid-peaks/Sox2/profile/binsize=10/imbalance 0.7339108910891089\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          eval/valid-peaks/Sox2/counts/mse 0.6502151489257812\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                eval/valid-peaks/Sox2/counts/var_explained 0.0862531065940857\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     eval/valid-peaks/Sox2/counts/pearsonr 0.36199269261264533\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                    eval/valid-peaks/Sox2/counts/spearmanr 0.3506800526944667\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          eval/valid-peaks/Sox2/counts/mad 0.6565879583358765\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            eval/valid-peaks/Nanog/profile/binsize=1/auprc 0.5859119403432145\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     eval/valid-peaks/Nanog/profile/binsize=1/random_auprc 0.0982463910867325\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      eval/valid-peaks/Nanog/profile/binsize=1/n_positives 57470\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    eval/valid-peaks/Nanog/profile/binsize=1/frac_ambigous 0.27505718547986074\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/valid-peaks/Nanog/profile/binsize=1/imbalance 0.09855198715926083\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           eval/valid-peaks/Nanog/profile/binsize=10/auprc 0.8997501954872384\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    eval/valid-peaks/Nanog/profile/binsize=10/random_auprc 0.6247912670442766\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     eval/valid-peaks/Nanog/profile/binsize=10/n_positives 25123\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   eval/valid-peaks/Nanog/profile/binsize=10/frac_ambigous 0.5016036797613128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       eval/valid-peaks/Nanog/profile/binsize=10/imbalance 0.6266493726771595\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                         eval/valid-peaks/Nanog/counts/mse 1.1316605806350708\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               eval/valid-peaks/Nanog/counts/var_explained 0.12737709283828735\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                    eval/valid-peaks/Nanog/counts/pearsonr 0.3727536560231944\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/valid-peaks/Nanog/counts/spearmanr 0.35026001617462593\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                         eval/valid-peaks/Nanog/counts/mad 0.8763851523399353\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              eval/valid-peaks/avg/profile/binsize=1/auprc 0.5861564205725561\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       eval/valid-peaks/avg/profile/binsize=1/random_auprc 0.10413657532055527\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/valid-peaks/avg/profile/binsize=1/n_positives 26248.333333333332\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      eval/valid-peaks/avg/profile/binsize=1/frac_ambigous 0.28105859328807065\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/valid-peaks/avg/profile/binsize=1/imbalance 0.1035917041177088\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             eval/valid-peaks/avg/profile/binsize=10/auprc 0.9290821328542807\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      eval/valid-peaks/avg/profile/binsize=10/random_auprc 0.7146429014192877\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       eval/valid-peaks/avg/profile/binsize=10/n_positives 12010.333333333334\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     eval/valid-peaks/avg/profile/binsize=10/frac_ambigous 0.4993927870258328\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         eval/valid-peaks/avg/profile/binsize=10/imbalance 0.7136500246634127\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                           eval/valid-peaks/avg/counts/mse 0.8712821006774902\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 eval/valid-peaks/avg/counts/var_explained 0.10024905204772949\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/valid-peaks/avg/counts/pearsonr 0.35943538042216433\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     eval/valid-peaks/avg/counts/spearmanr 0.3387720562278769\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                           eval/valid-peaks/avg/counts/mad 0.755818784236908\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             eval/train-peaks/Oct4/profile/binsize=1/auprc 0.6021819679111583\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      eval/train-peaks/Oct4/profile/binsize=1/random_auprc 0.1090942526242791\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       eval/train-peaks/Oct4/profile/binsize=1/n_positives 30625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     eval/train-peaks/Oct4/profile/binsize=1/frac_ambigous 0.29469681908548706\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         eval/train-peaks/Oct4/profile/binsize=1/imbalance 0.10790517733445143\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            eval/train-peaks/Oct4/profile/binsize=10/auprc 0.946456019841667\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     eval/train-peaks/Oct4/profile/binsize=10/random_auprc 0.776684594893082\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      eval/train-peaks/Oct4/profile/binsize=10/n_positives 15747\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    eval/train-peaks/Oct4/profile/binsize=10/frac_ambigous 0.49358846918489063\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/train-peaks/Oct4/profile/binsize=10/imbalance 0.7727451172833448\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          eval/train-peaks/Oct4/counts/mse 0.8595675826072693\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                eval/train-peaks/Oct4/counts/var_explained 0.07855808734893799\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     eval/train-peaks/Oct4/counts/pearsonr 0.3099009113916154\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                    eval/train-peaks/Oct4/counts/spearmanr 0.2873417612340714\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          eval/train-peaks/Oct4/counts/mad 0.7519600987434387\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             eval/train-peaks/Sox2/profile/binsize=1/auprc 0.6687051671525351\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      eval/train-peaks/Sox2/profile/binsize=1/random_auprc 0.10865745143248316\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       eval/train-peaks/Sox2/profile/binsize=1/n_positives 5603\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     eval/train-peaks/Sox2/profile/binsize=1/frac_ambigous 0.2707022471910112\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         eval/train-peaks/Sox2/profile/binsize=1/imbalance 0.1079035550591226\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            eval/train-peaks/Sox2/profile/binsize=10/auprc 0.9499068413718156\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     eval/train-peaks/Sox2/profile/binsize=10/random_auprc 0.7215290630981378\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      eval/train-peaks/Sox2/profile/binsize=10/n_positives 2623\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    eval/train-peaks/Sox2/profile/binsize=10/frac_ambigous 0.4872191011235955\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/train-peaks/Sox2/profile/binsize=10/imbalance 0.7184333059435771\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          eval/train-peaks/Sox2/counts/mse 0.6751421093940735\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                eval/train-peaks/Sox2/counts/var_explained 0.0824962854385376\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     eval/train-peaks/Sox2/counts/pearsonr 0.35352961544031347\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                    eval/train-peaks/Sox2/counts/spearmanr 0.3371034925703734\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          eval/train-peaks/Sox2/counts/mad 0.6665996313095093\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            eval/train-peaks/Nanog/profile/binsize=1/auprc 0.6175686334240247\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     eval/train-peaks/Nanog/profile/binsize=1/random_auprc 0.09805910353418598\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      eval/train-peaks/Nanog/profile/binsize=1/n_positives 101187\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    eval/train-peaks/Nanog/profile/binsize=1/frac_ambigous 0.2719046267385751\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/train-peaks/Nanog/profile/binsize=1/imbalance 0.09861973115848238\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           eval/train-peaks/Nanog/profile/binsize=10/auprc 0.9107511134763839\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    eval/train-peaks/Nanog/profile/binsize=10/random_auprc 0.6207859932685165\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     eval/train-peaks/Nanog/profile/binsize=10/n_positives 43972\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   eval/train-peaks/Nanog/profile/binsize=10/frac_ambigous 0.4973389156968493\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       eval/train-peaks/Nanog/profile/binsize=10/imbalance 0.6207665701983482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                         eval/train-peaks/Nanog/counts/mse 1.1610476970672607\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               eval/train-peaks/Nanog/counts/var_explained 0.12104427814483643\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                    eval/train-peaks/Nanog/counts/pearsonr 0.3620179513612261\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/train-peaks/Nanog/counts/spearmanr 0.3385852849092467\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                         eval/train-peaks/Nanog/counts/mad 0.8907265663146973\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              eval/train-peaks/avg/profile/binsize=1/auprc 0.6294852561625727\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       eval/train-peaks/avg/profile/binsize=1/random_auprc 0.10527026919698275\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/train-peaks/avg/profile/binsize=1/n_positives 45805.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      eval/train-peaks/avg/profile/binsize=1/frac_ambigous 0.27910123100502443\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/train-peaks/avg/profile/binsize=1/imbalance 0.10480948785068546\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             eval/train-peaks/avg/profile/binsize=10/auprc 0.9357046582299556\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      eval/train-peaks/avg/profile/binsize=10/random_auprc 0.7063332170865788\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       eval/train-peaks/avg/profile/binsize=10/n_positives 20780.666666666668\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     eval/train-peaks/avg/profile/binsize=10/frac_ambigous 0.49271549533511183\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         eval/train-peaks/avg/profile/binsize=10/imbalance 0.7039816644750901\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                           eval/train-peaks/avg/counts/mse 0.8985857963562012\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 eval/train-peaks/avg/counts/var_explained 0.094032883644104\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/train-peaks/avg/counts/pearsonr 0.3418161593977183\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     eval/train-peaks/avg/counts/spearmanr 0.3210101795712305\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                           eval/train-peaks/avg/counts/mad 0.7697620987892151\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced: https://app.wandb.ai/avsec/bpnet-demo/runs/2021-06-13_21-04-25_60667d18-3bc0-48c1-ae7a-8fce4360ba26\n"
     ]
    }
   ],
   "source": [
    "# setup a new run_id (could be done automatically, but then the output directory would change)\n",
    "run_id = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\") + \"_\" + str(uuid.uuid4())\n",
    "\n",
    "# Train for at most 10 epochs\n",
    "!cd {exp_dir} && bpnet train dataspec.yml --premade=bpnet9 --config=config.gin . --override='train.epochs=10' --run-id '{run_id}' --wandb=avsec/bpnet-demo --in-memory\n",
    "\n",
    "# softlink the new output directory\n",
    "!rm {exp_dir}/output && ln -srf {exp_dir}/{run_id}  {exp_dir}/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-5ABo-OF2GjQ",
    "outputId": "954da98f-6f4c-4f95-af3e-dc7c52c56f57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING:tensorflow:From /home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "2021-06-13 20:59:15,026 [WARNING] From /home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "2021-06-13 20:59:16,110 [INFO] Note: detected 112 virtual cores but NumExpr set to maximum of 64, check \"NUMEXPR_MAX_THREADS\" environment variable.\n",
      "2021-06-13 20:59:16,110 [INFO] Note: NumExpr detected 112 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2021-06-13 20:59:16,110 [INFO] NumExpr defaulting to 8 threads.\n",
      "Error.  nthreads cannot be larger than environment variable \"NUMEXPR_MAX_THREADS\" (64)/home/ubuntu/miniconda3/envs/bpnet/lib/python3.6/site-packages/bpnet-0.0.23-py3.6.egg/bpnet/plot/heatmaps.py:6: MatplotlibDeprecationWarning: \n",
      "The mpl_toolkits.axes_grid1.colorbar module was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use matplotlib.colorbar instead.\n",
      "  from mpl_toolkits.axes_grid1.colorbar import colorbar\n",
      "usage: bpnet train [-h] [--premade PREMADE] [--config CONFIG]\n",
      "                   [--override OVERRIDE] [--gpu GPU]\n",
      "                   [--memfrac-gpu MEMFRAC_GPU] [--num-workers NUM_WORKERS]\n",
      "                   [--vmtouch] [--in-memory] [--wandb-project WANDB_PROJECT]\n",
      "                   [--cometml-project COMETML_PROJECT] [--run-id RUN_ID]\n",
      "                   [--note-params NOTE_PARAMS] [--overwrite]\n",
      "                   dataspec output_dir\n",
      "\n",
      "Train a model using gin-config\n",
      "\n",
      "    Output files:\n",
      "      train.log - log file\n",
      "      model.h5 - Keras model HDF5 file\n",
      "      seqmodel.pkl - Serialized SeqModel. This is the main trained model.\n",
      "      eval-report.ipynb/.html - evaluation report containing training loss curves and some example model predictions.\n",
      "        You can specify your own ipynb using `--override='report_template.name=\"my-template.ipynb\"'`.\n",
      "      model.gin -> copied from the input\n",
      "      dataspec.yaml -> copied from the input\n",
      "    \n",
      "\n",
      "positional arguments:\n",
      "  dataspec              dataspec.yaml file\n",
      "  output_dir            where to store the results. Note: a subdirectory\n",
      "                        `run_id` will be created in `output_dir`.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --premade PREMADE     pre-made config file to use (e.g. use the default\n",
      "                        architecture). See TODO - X for available premade\n",
      "                        models. (default: 'bpnet9')\n",
      "  --config CONFIG       gin config file path(s) specifying the model\n",
      "                        architecture and the loss etc. They override the\n",
      "                        premade model. Single model example: config.gin.\n",
      "                        Multiple file example: data.gin,model.gin (default: -)\n",
      "  --override OVERRIDE   semi-colon separated list of additional gin bindings\n",
      "                        to use (default: '')\n",
      "  --gpu GPU             which gpu to use. Example: gpu=1 (default: 0)\n",
      "  --memfrac-gpu MEMFRAC_GPU\n",
      "                        what fraction of the GPU memory to use (default: 0.45)\n",
      "  --num-workers NUM_WORKERS\n",
      "                        number of workers to use in parallel for loading the\n",
      "                        data the model (default: 8)\n",
      "  --vmtouch             if True, use vmtouch to load the files in dataspec\n",
      "                        into Linux page cache (default: False)\n",
      "  --in-memory           if True, load the entire dataset into the memory first\n",
      "                        (default: False)\n",
      "  --wandb-project WANDB_PROJECT\n",
      "                        path to the wandb (https://www.wandb.com/) project\n",
      "                        name `<entity>/<project>`. Example: Avsecz/test. This\n",
      "                        will track and upload your metrics. Make sure you have\n",
      "                        specified the following environemnt variable: TODO. If\n",
      "                        not specified, wandb will not be used (default: '')\n",
      "  --cometml-project COMETML_PROJECT\n",
      "                        path to the comet.ml (https://www.comet.ml/) project\n",
      "                        specified as <username>/<project>. This will track and\n",
      "                        upload your metrics. Make sure you have specified the\n",
      "                        following environemnt variable: TODO. If not\n",
      "                        specified, cometml will not get used (default: '')\n",
      "  --run-id RUN_ID       manual run id. If not specified, it will be either\n",
      "                        randomly generated or re-used from wandb or comet.ml.\n",
      "                        (default: -)\n",
      "  --note-params NOTE_PARAMS\n",
      "                        take note of additional key=value pairs. Example:\n",
      "                        --note-params note=\"my custom note\",feature_set=this\n",
      "                        (default: '')\n",
      "  --overwrite           if True, the output directory will be overwritten\n",
      "                        (default: False)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# To see `bpnet train` docs run the following cell\n",
    "!bpnet train -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjo4JIOLyjbh"
   },
   "source": [
    "### View the evaluation results\n",
    "\n",
    "`bpnet train` produces the following output files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "3o_U-Fu2C0fU",
    "outputId": "0be96454-bb19-48e5-ae1c-44bea6d5b271"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access 'bpnet/examples/chip-nexus/output/': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls -latr {model_dir}/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_eGVXT_oC9uJ"
   },
   "source": [
    "The main output files are:\n",
    "\n",
    "- model.h5 - Keras model HDF5 file\n",
    "- seq_model.pkl - Serialized SeqModel. This is the main trained model.\n",
    "- eval-report.ipynb/.html - evaluation report containing training loss curves and some example model predictions.\n",
    "- model.gin -> copied from the input\n",
    "- dataspec.yaml -> copied from the input\n",
    "\n",
    "看 evaluation 直接点这[http://132.232.36.144:9090/notebooks/bpnet/examples/chip-nexus/output/evaluate.ipynb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "LQfbhhaAx-U2",
    "outputId": "81f3513e-a5d7-4599-97d6-eb1326fac15c"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'bpnet/examples/chip-nexus/output/evaluate.html'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-92fcf16e40cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'evaluate.html'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/bpnet/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Consider using IPython.display.IFrame instead\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHTML\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_html_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bpnet/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[1;32m    628\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bpnet/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'bpnet/examples/chip-nexus/output/evaluate.html'"
     ]
    }
   ],
   "source": [
    "HTML(filename=model_dir / 'evaluate.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ePihEJ93niU"
   },
   "source": [
    "## 3. Tweak the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FWWOH93f3oes"
   },
   "source": [
    "### Modify the hyper-parameters\n",
    "\n",
    "The first step you can do to improve your model is to adapt the hyper-parameters of the existing model. Have a look at the default hyper-parameters of the pre-made model you were using here: [../bpnet/premade/bpnet9.gin](../bpnet/premade/bpnet9.gin). You can directly override the hyper-parameters from the command line as follows:\n",
    "\n",
    "```bash\n",
    "bpnet train dataspec.yaml --premade=bpnet9 --override='train.lr=0.05;model.multi_task_model.n_layers=5' -o trained_model/\n",
    "```\n",
    "\n",
    "This will use a different learning rate (0.05) and less convolutional layers (5) by overriding the original values. Note that multiple parameter specifications were separated using `;`. If you find it impractical to specify the hyper-parameters from the CLI, you can instead specify them in the `model.gin` config file: \n",
    "\n",
    "```python\n",
    "train.lr = 0.05\n",
    "model.multi_task_model.n_layers = 5\n",
    "```\n",
    "\n",
    "and then run `bpnet train` as follows:\n",
    "\n",
    "```bash\n",
    "bpnet train dataspec.yaml --premade=bpnet9 --config=model.gin -o trained_model/\n",
    "```\n",
    "\n",
    "Note that you can use `--override` and `--config` simultaneusly. If both specify the same parameter, then the one specified by `--override` will be used. For example, the following command will use the learning rate of 0.01.\n",
    "\n",
    "```bash\n",
    "bpnet train dataspec.yaml --premade=bpnet9 --config=model.gin --override='train.lr=0.01' -o trained_model/\n",
    "```\n",
    "\n",
    "Altogether, `--config` overrides the parameters specified by `--premade`; `--override` overrides parameters specified by `--config` and `--premade` (e.g. `--override` > `--config` > `--premade`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rz9AbHsB4VcO"
   },
   "source": [
    "### Specify your own model architecture, loss function or training procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hnxRFPIA4XMN"
   },
   "source": [
    "Have a look at the [gin-config documentation](https://github.com/google/gin-config) to learn more about the gin config files. This will help you understand how you can utilize them effectively and thereby go beyond the premade models. To specify your own architecture, use a different loss function or a different training procedure, you have to do three things:\n",
    "1. Implement a python function returning the `bpnet.seqmodel.SeqModel` object.\n",
    "2. Decorate the function with `@gin.configurable`\n",
    "3. Specify that you would like to use this model in the `model.gin` config file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPUZ9tFpDRs6"
   },
   "source": [
    "#### How do I specify my own jupyter notebook for evaluation?\n",
    "\n",
    "You can specify your own jupyter notebook by specifying the `train.eval_report='<path>.ipynb'` in either `config.gin` file or by specifying `--override='train.eval_report=\"<path>.ipynb\"'`. Make sure to copy the first cell of https://github.com/kundajelab/bpnet/blob/master/bpnet/templates/evaluate.ipynb to your template notebook as it contains the following cell metadata: `{\"tags\": [\"parameters\"]}`. See https://github.com/nteract/papermill#parameterizing-a-notebook on how to set this yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20E9i3P-4a65"
   },
   "source": [
    "#### What is `bpnet.seqmodel.SeqModel`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4qYepF3q4cz5"
   },
   "source": [
    "`SeqModel` is a wrapper around the Keras model. It requires the input to be a one-hot-encoded DNA sequence and it consists of two key components: body and heads. Body will process the input sequence with multiple layers yielding the bottleneck activation map which can be seens as containing an embedding at each nucleotide position. Heads will take the bottleneck activation map as input and they will output the final model predictions. Heads specify the loss function and the evaluation metric. They can additionally accept the bias/control track as input and control for it in the loss function. The benefit of restricting the model architecture in that way is that the sequence contribution scores can be automatically computed with no extra code. Have a look at the `SeqModel` [source code](../bpnet/seqmodel.py) to learn more about it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IOJBSGpEkwQd"
   },
   "source": [
    "# Compute contribution scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "cmVa5iy6vCHG",
    "outputId": "35fd8af9-555f-495d-e4f6-189c2b4ff777"
   },
   "outputs": [],
   "source": [
    "# contribution scores\n",
    "!bpnet contrib {model_dir} --method=deeplift --memfrac-gpu=1 --contrib-wildcard='*/profile/wn' {contrib_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "usHrEbAwz2bF",
    "outputId": "37a607b2-9b13-4f15-d704-ecc3334102a5"
   },
   "outputs": [],
   "source": [
    "# null contribution scores obtained by shuffling the sequences.\n",
    "!bpnet contrib {model_dir} --method=deeplift --memfrac-gpu=1 --shuffle-seq --max-regions 5000 --contrib-wildcard='*/profile/wn' {contrib_null_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "iVzLYOe64RwE",
    "outputId": "684a99ff-1f1b-46b0-8f86-603e680eabfe"
   },
   "outputs": [],
   "source": [
    "# To see `bpnet contrib` docs run the following cell\n",
    "!bpnet contrib -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A4wvz0LDxAa0"
   },
   "source": [
    "### Visualize the contribution scores\n",
    "\n",
    "Previous command generates an HDF5 file `contrib_file` containing the contribution scores. You can access the the values stored in this file by using the `ContribFile` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qeuLO79OcPMj"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from bpnet.cli.contrib import ContribFile\n",
    "from bpnet.plot.tracks import plot_tracks, to_neg\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cf = ContribFile(contrib_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6WTnMJjDqzSU"
   },
   "outputs": [],
   "source": [
    "# get chip-nexus profiles and contribution scores from the ContribFile\n",
    "profiles = cf.get_profiles()\n",
    "contrib_scores = cf.get_contrib()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "-aYDwChjq5jG",
    "outputId": "fbb7b841-94b7-4afe-bebb-68e5fd26ae13"
   },
   "outputs": [],
   "source": [
    "# get example idx with most chip-nexus counts for each task\n",
    "examples = list({v.max(axis=-2).mean(axis=-1).argmax() for k,v in profiles.items()})\n",
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sMmx5gS9vabI"
   },
   "outputs": [],
   "source": [
    "tasks = ['Oct4', 'Sox2', 'Nanog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "DW13lCozr7Io",
    "outputId": "974141a0-fa8f-4b1e-c8b4-41d9b3c387f3"
   },
   "outputs": [],
   "source": [
    "xrange = slice(50, 150)\n",
    "for idx in examples:\n",
    "  plot_tracks({**{'profile/' + k: to_neg(v[idx,xrange]) for k,v in profiles.items()},\n",
    "               **{'contrib/' + k:v[idx,xrange] for k,v in contrib_scores.items()}},\n",
    "             title=idx,\n",
    "             rotate_y=0,\n",
    "             fig_width=10,\n",
    "             fig_height_per_track=1);\n",
    "  sns.despine(top=True, right=True, bottom=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RPN3ylt0GbmE"
   },
   "source": [
    "Have a look at the [ContribFile API](https://github.com/kundajelab/bpnet/blob/0cb7277b736260f8b4084c9b0c5bd62b9edb5266/bpnet/cli/contrib.py#L262) to explore all the available methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LiYC0MqlFFwm"
   },
   "source": [
    " ## Export BigWig files containing contribution scores and model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "yBsZ4aPXAaBm",
    "outputId": "fc4d926e-3087-4c92-aff0-71c431221eca"
   },
   "outputs": [],
   "source": [
    "!bpnet export-bw {model_dir} {model_dir}/bigwigs/ --contrib-method=deeplift --scale-contribution\n",
    "# scale-contribution will multiply the contribution scores with total count predictions\n",
    "# this will ensure that regions without high counts won't get high contribution scores\n",
    "# We generally recommend using --scale-contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "V1rYfRiqJT2B",
    "outputId": "9b7926a1-6fd8-4428-8dd3-3afb28bd776c"
   },
   "outputs": [],
   "source": [
    "!ls -latr {model_dir}/bigwigs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIazCIksA_6n"
   },
   "source": [
    "You  could visualize these files in the genome browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrYb5BddpHGU"
   },
   "source": [
    "# Run TF-MoDISco to discover motifs\n",
    "\n",
    "Next step is to cluster the contribution scores into motifs using TF-MoDISco. At first, we will cluster the Oct4 contribution scores in Oct4 peaks (`--only-task-regions`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hQP8L3-1pI-x"
   },
   "outputs": [],
   "source": [
    "task = 'Oct4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "abyWtlYa0IUx",
    "outputId": "1c75f08c-9e18-4b2a-9d42-79fec7784f68"
   },
   "outputs": [],
   "source": [
    "# Run modisco only for the Oct4 task\n",
    "!bpnet modisco-run {contrib_file} --null-contrib-file={contrib_null_file} --contrib-wildcard={task}/profile/wn --premade=modisco-50k --override='TfModiscoWorkflow.min_metacluster_size=1000' --only-task-regions {modisco_dir}/{task}/ --overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7F3FklwxyI9j",
    "outputId": "4bc9345c-45c4-49c3-d17d-2c10460cd739"
   },
   "outputs": [],
   "source": [
    "# View the modisco results\n",
    "HTML(filename=modisco_dir / 'Oct4/modisco.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03llxRt9o3mG"
   },
   "source": [
    "## Visualizing modisco results\n",
    "\n",
    "Here is an example how you can access the `modisco.h5` file in python and visualize the results yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "WgMFaCJSnm3n",
    "outputId": "9b2245ff-aaf2-4387-b7a5-c1a7d8e962e3"
   },
   "outputs": [],
   "source": [
    "# Modisco generated the following files for each TF\n",
    "!ls -latrh {modisco_dir}/{task}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pyvyVGEyl2iX"
   },
   "outputs": [],
   "source": [
    "from bpnet.modisco.files import ModiscoFile, ModiscoFileGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "XWldS4e3nE1U",
    "outputId": "cb1bf0b5-9ac9-4972-f95e-1aadffd83d1b"
   },
   "outputs": [],
   "source": [
    "# Alternative way of loading the files\n",
    "mf = ModiscoFile(modisco_dir /  'Oct4/modisco.h5')\n",
    "\n",
    "for p in mf.patterns():\n",
    "  n_seqlets = mf.n_seqlets(p.name)\n",
    "  p.plot(\"seq_ic\", title=f\"{p.name} ({n_seqlets})\")\n",
    "  plt.ylim([0, 2])\n",
    "  sns.despine(top=True, bottom=True, right=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HHkFUAyjr3vz"
   },
   "source": [
    "## Visualize the ChIP-nexus heatmaps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mRiSxDNCLTiI"
   },
   "outputs": [],
   "source": [
    "# load seqlets for the main motif\n",
    "mf = ModiscoFile(modisco_dir /  'Oct4/modisco.h5')\n",
    "seqlets = mf._get_seqlets('metacluster_0/pattern_0')\n",
    "\n",
    "# load the ContribFile\n",
    "# NOTE: we have to load it using `from_modisco_dir` since\n",
    "# modisco was executed only on a subset of the\n",
    "# regions present in ContribFile\n",
    "cf = ContribFile.from_modisco_dir(modisco_dir / 'Oct4')\n",
    "\n",
    "# extract into `StackedSeqletContrib`\n",
    "sc = cf.extract(seqlets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_zV1HiKFMWz_",
    "outputId": "4e393336-99db-48fe-937d-ffab9328f52a"
   },
   "outputs": [],
   "source": [
    "sc.plot(kind='profile_agg', figsize_tmpl=(3.3, 2));\n",
    "sc.plot(kind='profile', figsize=(10, 8));\n",
    "sc.plot(kind='seq',figsize_tmpl=(13, 10));\n",
    "plt.title(\"Sequence\");\n",
    "# sc.plot(kind='contrib', figsize=(10, 8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uBLGYVxqE71P"
   },
   "source": [
    "## Generating further reports\n",
    "\n",
    "For analyzing ChIP-nexus/exo/seq data, there exist an additional report generated by `bpnet chip-nexus analysis` after running modisco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "JFNPvW2OJrKT",
    "outputId": "5110a333-768e-464f-f9df-71a3c07108e8"
   },
   "outputs": [],
   "source": [
    "# generate more extensive reports specific for ChIP-nexus/exo data\n",
    "# We'll use a slightly smaller footprint width since the seqlets may run out of chromosomes instead\n",
    "!bpnet chip-nexus-analysis {modisco_dir}/Oct4 --footprint-width=150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "id": "V3HeqmjXKt7y",
    "outputId": "f4f245fa-564e-4086-8f93-1314b83ad8f0"
   },
   "outputs": [],
   "source": [
    "# This prouced new files to the output directory\n",
    "!ls -latr {modisco_dir}/Oct4/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "resources": {
      "http://localhost:8080/custom.css": {
       "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
       "headers": [
        [
         "content-length",
         "1449"
        ],
        [
         "content-type",
         "text/html; charset=utf-8"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      },
      "http://localhost:8080/plots/metacluster_0/pattern_0/agg_profile_contribcores.png": {
       "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
       "headers": [
        [
         "content-length",
         "1449"
        ],
        [
         "content-type",
         "text/html; charset=utf-8"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      },
      "http://localhost:8080/plots/metacluster_0/pattern_0/agg_profile_hypcontribscores.png": {
       "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
       "headers": [
        [
         "content-length",
         "1449"
        ],
        [
         "content-type",
         "text/html; charset=utf-8"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      },
      "http://localhost:8080/plots/metacluster_0/pattern_0/contrib_counts.png": {
       "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
       "headers": [
        [
         "content-length",
         "1449"
        ],
        [
         "content-type",
         "text/html; charset=utf-8"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      },
      "http://localhost:8080/plots/metacluster_0/pattern_0/contrib_profile.png": {
       "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
       "headers": [
        [
         "content-length",
         "1449"
        ],
        [
         "content-type",
         "text/html; charset=utf-8"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      },
      "http://localhost:8080/plots/metacluster_0/pattern_0/heatmap_seq.png": {
       "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
       "headers": [
        [
         "content-length",
         "1449"
        ],
        [
         "content-type",
         "text/html; charset=utf-8"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      },
      "http://localhost:8080/plots/metacluster_0/pattern_0/profile_aggregated.png": {
       "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
       "headers": [
        [
         "content-length",
         "1449"
        ],
        [
         "content-type",
         "text/html; charset=utf-8"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      },
      "http://localhost:8080/plots/metacluster_0/pattern_0/profile_heatmap.png": {
       "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
       "headers": [
        [
         "content-length",
         "1449"
        ],
        [
         "content-type",
         "text/html; charset=utf-8"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      },
      "http://localhost:8080/plots/metacluster_0/pattern_1/agg_profile_contribcores.png": {
       "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
       "headers": [
        [
         "content-length",
         "1449"
        ],
        [
         "content-type",
         "text/html; charset=utf-8"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      },
      "http://localhost:8080/plots/metacluster_0/pattern_1/agg_profile_hypcontribscores.png": {
       "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
       "headers": [
        [
         "content-length",
         "1449"
        ],
        [
         "content-type",
         "text/html; charset=utf-8"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      },
      "http://localhost:8080/plots/metacluster_0/pattern_1/contrib_counts.png": {
       "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
       "headers": [
        [
         "content-length",
         "1449"
        ],
        [
         "content-type",
         "text/html; charset=utf-8"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      },
      "http://localhost:8080/plots/metacluster_0/pattern_1/contrib_profile.png": {
       "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
       "headers": [
        [
         "content-length",
         "1449"
        ],
        [
         "content-type",
         "text/html; charset=utf-8"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      },
      "http://localhost:8080/plots/metacluster_0/pattern_1/heatmap_seq.png": {
       "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
       "headers": [
        [
         "content-length",
         "1449"
        ],
        [
         "content-type",
         "text/html; charset=utf-8"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      },
      "http://localhost:8080/plots/metacluster_0/pattern_1/profile_aggregated.png": {
       "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
       "headers": [
        [
         "content-length",
         "1449"
        ],
        [
         "content-type",
         "text/html; charset=utf-8"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      },
      "http://localhost:8080/plots/metacluster_0/pattern_1/profile_heatmap.png": {
       "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
       "headers": [
        [
         "content-length",
         "1449"
        ],
        [
         "content-type",
         "text/html; charset=utf-8"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      },
      "http://localhost:8080/plots/metacluster_0/pattern_2/agg_profile_contribcores.png": {
       "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
       "headers": [
        [
         "content-length",
         "1449"
        ],
        [
         "content-type",
         "text/html; charset=utf-8"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      },
      "http://localhost:8080/plots/metacluster_0/pattern_2/agg_profile_hypcontribscores.png": {
       "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
       "headers": [
        [
         "content-length",
         "1449"
        ],
        [
         "content-type",
         "text/html; charset=utf-8"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      },
      "http://localhost:8080/plots/metacluster_0/pattern_2/contrib_counts.png": {
       "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
       "headers": [
        [
         "content-length",
         "1449"
        ],
        [
         "content-type",
         "text/html; charset=utf-8"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      },
      "http://localhost:8080/plots/metacluster_0/pattern_2/contrib_profile.png": {
       "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
       "headers": [
        [
         "content-length",
         "1449"
        ],
        [
         "content-type",
         "text/html; charset=utf-8"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      },
      "http://localhost:8080/plots/metacluster_0/pattern_2/heatmap_seq.png": {
       "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
       "headers": [
        [
         "content-length",
         "1449"
        ],
        [
         "content-type",
         "text/html; charset=utf-8"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      },
      "http://localhost:8080/plots/metacluster_0/pattern_2/profile_aggregated.png": {
       "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
       "headers": [
        [
         "content-length",
         "1449"
        ],
        [
         "content-type",
         "text/html; charset=utf-8"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      },
      "http://localhost:8080/plots/metacluster_0/pattern_2/profile_heatmap.png": {
       "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
       "headers": [
        [
         "content-length",
         "1449"
        ],
        [
         "content-type",
         "text/html; charset=utf-8"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      }
     }
    },
    "id": "XpTEISChKW0S",
    "outputId": "be03bbb9-10e9-4156-a950-be0f4d66a918"
   },
   "outputs": [],
   "source": [
    "# NOTE: the heatmap files will not be displayed here since \n",
    "# the file paths of the plots are not correct.\n",
    "HTML(f\"{modisco_dir}/Oct4/modisco-chip.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zz3PKAaAphOp"
   },
   "source": [
    "## Running modisco for the remaining tasks\n",
    "\n",
    "Next, we will run modisco on the contribution scores for the remaining tasks: Sox2 and Nanog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W_1G-bpSpwJN"
   },
   "outputs": [],
   "source": [
    "tasks = ['Oct4', 'Sox2', 'Nanog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "blF8FUclpmkj",
    "outputId": "959c63a4-a6fe-4ad3-c358-194d929d76d6"
   },
   "outputs": [],
   "source": [
    "# Run modisco only for the Nanog task\n",
    "for task in tasks:\n",
    "  if task == 'Oct4':\n",
    "    # already exists from before\n",
    "    continue\n",
    "  print(f\"task: {task}\")\n",
    "  !bpnet modisco-run {contrib_file} --null-contrib-file={contrib_null_file} --override='TfModiscoWorkflow.min_metacluster_size = 1000' --contrib-wildcard={task}/profile/wn --only-task-regions --premade=modisco-50k {modisco_dir}/{task}/ --overwrite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSLNHnDozk5m"
   },
   "source": [
    "### Visualizing the results\n",
    "\n",
    "You can now use `MultipleModiscoResult` class to handle multiple `ModiscoResult` objects and visualize motifs discovered in all the tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qdjp534il3pb"
   },
   "outputs": [],
   "source": [
    "# MultipleModiscoResult is a convenience wrapper around ModiscoResult\n",
    "mf = ModiscoFileGroup({t: ModiscoFile(modisco_dir / t / 'modisco.h5') for t in tasks})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "id": "RpR9Xf_UmIJp",
    "outputId": "8cdc20fa-f9fe-434e-e092-3fd18d228ae7"
   },
   "outputs": [],
   "source": [
    "# Plot all the patterns\n",
    "for p in mf.patterns():\n",
    "  p.plot(\"seq_ic\", title=f\"{p.name} ({mf.n_seqlets(p.name)})\")\n",
    "  plt.ylim([0, 2])\n",
    "  sns.despine(top=True, bottom=True, right=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EOG-FOIwy755"
   },
   "source": [
    "# Get motif instances with CWM scanning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MoG0Rh3K2U-j"
   },
   "source": [
    "To get motif instances in the genome, we will use CWM scanning using the `bpnet cwm-scan` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 802
    },
    "id": "cPgWDeOc03fb",
    "outputId": "6dcf5943-51bd-4712-dee3-26c9e555eab5"
   },
   "outputs": [],
   "source": [
    "!bpnet cwm-scan -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7k-iXVV12ZXb"
   },
   "source": [
    "We will run CWM scanning across the regions of all peaks, not just peaks of the TF for which TF-MoDISco was ran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2jCjmDWQ1AF1",
    "outputId": "c18547b7-7a9f-4317-8384-22a4b63f0760"
   },
   "outputs": [],
   "source": [
    "# run CWM scanning for each task\n",
    "for task in tasks:\n",
    "  !bpnet cwm-scan {modisco_dir}/{task} {modisco_dir}/{task}/motif-instances.tsv.gz --contrib-file {contrib_file} --add-profile-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vPqcs5mW280L"
   },
   "outputs": [],
   "source": [
    "# Let's load the resulting table:\n",
    "dfi = pd.read_csv(modisco_dir / 'Nanog/motif-instances.tsv.gz', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "x56EwBxNDukV",
    "outputId": "0c48deb3-c2d1-4c26-ea35-04e3b2df496b"
   },
   "outputs": [],
   "source": [
    "dfi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zDB2ZaOINLmO"
   },
   "source": [
    "### Column description of motif instance table a.k.a. `dfi`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDWe-gQ6DzMK"
   },
   "source": [
    "First seven columns are the most important ones. These represent the motif instance coordinates and the two scores derived from CWM scanning (contribution and match scores):\n",
    "- chrom\n",
    "- start\n",
    "- end\n",
    "- pattern name\n",
    "- contribution score ([0, 1], 1 = highest contribution, 0=lowest contribution)\n",
    "- strand. \n",
    "- CWM match score measuring the Jaccard similarity between CWM and the contribution scores ([0, 1], 1 = excellent match, 0=poor match)\n",
    "\n",
    "\n",
    "Here is the full column name description:\n",
    "\n",
    "***Motif instance position***\n",
    "- `example_chrom` - chromosome name\n",
    "- `pattern_start_abs` - chromosome start position (0-based, same as BED files)\n",
    "- `pattern_end_abs` - chromosome end position (0-based, same as BED files)\n",
    "- `pattern_len` - pattern length (same as `pattern_end_abs - pattern_start_abs`)\n",
    "- `pattern` - pattern name from TF-MoDISco (e.g. `metacluster_0/pattern_1`)\n",
    "- `pattern_short` - short pattern name from TF-MoDISco (e.g. `m0_p1`)\n",
    "- `strand` - strand of the motif instance match\n",
    "- `id` - unique ID for each motif instance (row number of the original pd.DataFrame)\n",
    "\n",
    "***Scanned region information***\n",
    "- `example_idx` - index of the scanned region. This corresponds to the item in the scanned `ContribFile`. \n",
    "- `example_start` - start position of the scanned region.\n",
    "- `example_end` - end of the scanned region.\n",
    "- `example_strand` - strand of the scanned region\n",
    "- `example_interval_from_task` - `task` for which the scanned region was derived (e.g. Oct4 means that that region was an Oct4 peak specified in `dataspec.yml`).\n",
    "\n",
    "***Relative motif region information***\n",
    "- `pattern_start` - start position within the region\n",
    "- `pattern_end` - end position within the regions\n",
    "- `pattern_center` - center position within the regions\n",
    "\n",
    "***PWM scan match***\n",
    "- `seq_match` - classical PWM match score\n",
    "\n",
    "***Contribution score amount***\n",
    "- `contrib/{task}` - Absolute amount of the contribution score for task `{task}` at the motif instance position.\n",
    "- `contrib_max` - maximum match value across all `contrib/{task}` columns\n",
    "- `contrib_max_task` - task name for which `contrib/{task}` is maximal\n",
    "- `contrib_weighted` - contribution score weighted across tasks. ***NOTE*** If only a single task was used to run modisco as it is the case in this tutorial, then `contrib/{task} = contrib_max = contrib_weighted`.\n",
    "- `contrib_weighted_cat` - contribution score category (low, medium, high). These were determined by partitioning contrib_weighted_p according to the intervals (0, 0.33], (0.33, 0.66], (0.66, 1]\n",
    "\n",
    "***CWM match***\n",
    "- `match/{task}` - Jaccard similarity between the contribution score for task `{task}` and the CWM\n",
    "- `match_max` - maximum match value across all `match/{task}` columns\n",
    "- `match_max_task` - task name for which `match/{task}` is maximal\n",
    "- `match_weighted` - contribution score weighted across tasks.  ***NOTE*** If only a single task was used to run modisco as it is the case in this tutorial, then `match/{task} = match_max = match_weighted`.\n",
    "- `match_weighted_cat` - contribution score quantile\n",
    "\n",
    "***Footprint evaluation (optional)***\n",
    "- `{task}/profile_max` - maximal number of footprint count in the 70 bp window at the motif instance\n",
    "- `{task}/profile_counts_max_ref` - number of counts at the position where the reference footprint is maximal (sum across strands).\n",
    "- `{task}/profile_match` - symmetric KL divergence between the original footprint and the observed footprint (footprint = 70 bp wide)\n",
    "- `{task}/profile_counts` - total number of counts of `{task}` in the 70 bp window at the motif instance\n",
    "\n",
    "\n",
    "***NOTE***: All the columns ending with ***`_p`*** contain the CDF values (value between 0 and 1) using the original TF-MoDISco seqlets to determine the distribution. \n",
    "\n",
    "See the `bpnet.modisco.pattern_instances` module for more function to interact with that table. Throughout the whole codebase, that table is refered to as `dfi` (**d**ata-***f***rame of ***i***nstances)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WvwepuBl1oM2"
   },
   "source": [
    "## Locus visualization with motif instances higlighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eG1ElN9eY8m"
   },
   "source": [
    "Let's visualize the same region as above, but this time highlighting differnet motif instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lMTDo9PcprPm"
   },
   "outputs": [],
   "source": [
    "from bpnet.utils import pd_col_prepend\n",
    "from bpnet.modisco.pattern_instances import dfi2seqlets\n",
    "from bpnet.modisco.utils import shorten_pattern, longer_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WJsLlvRqphr0"
   },
   "outputs": [],
   "source": [
    "# First load all the motif instances simultaneously\n",
    "dfi = pd.concat([pd.read_csv(modisco_dir / f'{task}/motif-instances.tsv.gz', sep='\\t').\n",
    "                 assign(tf=task).\n",
    "                 pipe(pd_col_prepend, ['pattern', 'pattern_short'], prefix=task + \"/\")  # prefix the pattern names with task name\n",
    "                 for task in tasks], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "acd5jVz0e5dj",
    "outputId": "f7b002b0-6a61-439c-d3b6-a0b98ce3483a"
   },
   "outputs": [],
   "source": [
    "idx = 1  # we'll use the same idx as displayed before\n",
    "\n",
    "# pattern instances in that locus\n",
    "dfi[dfi.example_idx == idx]\n",
    "\n",
    "# note that some instances have a poor match (match_weighted_p low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "TicDyPSuk1dN",
    "outputId": "6a4b8e5f-c466-4664-ed69-e24327660ced"
   },
   "outputs": [],
   "source": [
    "# convert dfi to Seqlet objects\n",
    "seqlets = [s.shift(-xrange.start)\n",
    "           for s in dfi2seqlets(dfi[dfi.example_idx == idx], short_name=True)]\n",
    "seqlets\n",
    "\n",
    "# # let's visualize these patterns\n",
    "# mf = ModiscoFileGroup({t: ModiscoFile(modisco_dir / f'{t}/modisco.h5') for t in tasks})\n",
    "# observed_patterns = {s.name for s in seqlets}  # get unique pattern names\n",
    "\n",
    "# for pn in observed_patterns:\n",
    "#   # NOTE: modisco requires the longer pattern version (e.g. {Task}/metacluster_0/pattern_1)\n",
    "#   pn_long = longer_pattern(pn)\n",
    "#   mf.get_pattern(pn_long).trim_seq_ic(0.08).plot('seq_ic')\n",
    "#   sns.despine(top=True, bottom=True, right=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "EHjJ8wEstS-H",
    "outputId": "a35b568e-9efb-44e3-a0f9-50f6551ab6d4"
   },
   "outputs": [],
   "source": [
    "# Visualize the locus with motif instances highlighted\n",
    "\n",
    "# get the contribution scores and profile score for that example idx\n",
    "xrange = slice(50, 150)\n",
    "cf = ContribFile(contrib_file)\n",
    "profiles = cf.get_profiles(idx=idx)\n",
    "contrib_scores = cf.get_contrib(idx=idx)\n",
    "\n",
    "\n",
    "# Let's focus only on the best match per track\n",
    "dfi_best = dfi[dfi.example_idx == idx].sort_values(\"match_weighted_p\", ascending=False).groupby('tf').first()\n",
    "\n",
    "seqlets = [s.shift(-xrange.start)\n",
    "           for s in dfi2seqlets(dfi_best, short_name=True)]\n",
    "\n",
    "\n",
    "plot_tracks({**{'profile/' + k: to_neg(v[xrange]) for k,v in profiles.items()},\n",
    "             **{'contrib/' + k:v[xrange] for k,v in contrib_scores.items()}},\n",
    "           title=idx,\n",
    "           rotate_y=0,\n",
    "           fig_width=10,\n",
    "           seqlets=[s.set_seqname('contrib/' + s.name.split(\"/\")[0]) for s in seqlets], # plot seqlets to the 'contrib/Nanog' track\n",
    "           fig_height_per_track=1);\n",
    "sns.despine(top=True, right=True, bottom=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nWtuB5BaeG3H"
   },
   "source": [
    "## ChIP-nexus heatmap visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 868
    },
    "id": "aL5NIuK0eNDC",
    "outputId": "a1eb77ec-a518-4efa-ace7-42e07a563ca3"
   },
   "outputs": [],
   "source": [
    "# get the chip-nexus data at the best motif isntances\n",
    "dfi = pd.read_csv(modisco_dir / 'Oct4/motif-instances.tsv.gz', sep='\\t')\n",
    "\n",
    "cf = ContribFile(contrib_file)\n",
    "\n",
    "# extract into `StackedSeqletContrib`\n",
    "sc = cf.extract_dfi(dfi.\n",
    "                    query(\"pattern_short == 'm0_p0'\").\n",
    "                    sort_values('contrib_weighted_p', ascending=False).iloc[:500], \n",
    "                    profile_width=50)\n",
    "\n",
    "sc.plot(kind='profile_agg', figsize_tmpl=(3.3, 2));\n",
    "sc.plot(kind='profile', figsize=(10, 8));\n",
    "sc.plot(kind='seq',figsize_tmpl=(13, 10));\n",
    "plt.title(\"Sequence\");\n",
    "# sc.plot(kind='contrib', figsize=(10, 8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vPyYS1rkehPw"
   },
   "source": [
    "## De-novo sequence scanning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6t9l-h2utMM"
   },
   "source": [
    "Say we would like to determine motif instances in a new sequence. Here is how to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "id": "ovPKEvmyu-Zl",
    "outputId": "8e010030-a7a1-4b46-94ff-f61b9d3ef92d"
   },
   "outputs": [],
   "source": [
    "# Load the SeqModel\n",
    "from bpnet.seqmodel import SeqModel\n",
    "\n",
    "# In case you get `Can't get attribute '_make_skeleton_class'` error, please restart the runtime\n",
    "# Runtime -> Reset runtimeb -> Yes\n",
    "sm = SeqModel.from_mdir(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "xM_Bz4kcyTvn",
    "outputId": "be6201d2-8b86-48ee-c4f7-dbf5c2af0dc4"
   },
   "outputs": [],
   "source": [
    "from bpnet.plot.tracks import filter_tracks, plot_tracks\n",
    "from concise.preprocessing import encodeDNA\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Core of the Oct4 enhancer sequence\n",
    "seq = 'N'*23 + 'GGAGGAACTGGGTGTGGGGAGGTTGTAGCCCGACCCTGCCCCTCCCCCCAGGGAGGTTGAGAGTTCTGGGCAGACGGCAGATGCATAACAAAGGTGCATGATAGCTCTGCCCTGGGGGCAGAGAAGATGGTTGGGGAGGGGTCCCTCTCGTCCTA' + 'N'*22\n",
    "seq_onehot = encodeDNA([seq]) # one-hot encode\n",
    "\n",
    "\n",
    "# Compute contribution scores\n",
    "contrib_scores = sm.contrib_score_all(seq_onehot, preact_only=True)\n",
    "contrib_scores = [(f'Contrib {k}', seq_onehot[0] * v[0])\n",
    "                  for k,v in contrib_scores.items()\n",
    "                  if k.endswith(\"profile/wn\")]  # keep only */profile/wn scores\n",
    "\n",
    "# Make predictions\n",
    "preds = sm.predict(seq_onehot)\n",
    "preds = [(f\"Pred {task}\", to_neg(preds[f\"{task}/profile\"][0]) * np.exp(preds[f\"{task}/counts\"][0]))\n",
    "         for task in sm.tasks]  # merge predictions\n",
    "\n",
    "viz_dict = OrderedDict(preds + contrib_scores)\n",
    "\n",
    "xlim = [50, 180]  # Focus only on the central\n",
    "viz_dict = filter_tracks(viz_dict, xlim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 100
    },
    "id": "2eonRGQyy4HI",
    "outputId": "c3a8793d-1732-43bc-e629-c6b1553574e6"
   },
   "outputs": [],
   "source": [
    "# determine the location of the first instance\n",
    "from bpnet.modisco.files import ModiscoFile\n",
    "\n",
    "mf = ModiscoFile(modisco_dir / 'Oct4/modisco.h5')\n",
    "pattern = mf.get_pattern(\"metacluster_0/pattern_0\").trim_seq_ic(0.08)  # get trimmed pattern\n",
    "task = 'Oct4'\n",
    "\n",
    "# scan the contribution scores + DNA sequence\n",
    "match, contribution = pattern.scan_contribution({task: dict(contrib_scores)[f'Contrib {task}/profile/wn'][np.newaxis]}, \n",
    "                                                 hyp_contrib=None, tasks=[task], n_jobs=1, verbose=False)\n",
    "seq_match = pattern.scan_seq(seq_onehot, n_jobs=1, verbose=False)\n",
    "\n",
    "# load the normalization table\n",
    "dfi_norm = pd.read_csv(f\"{modisco_dir}/{task}/cwm-scan-seqlets.trim-frac=0.08.csv.gz\")\n",
    "\n",
    "# get the motif instance table\n",
    "dfm = pattern.get_instances([task], match, contribution, seq_match,\n",
    "                            norm_df=dfi_norm[dfi_norm.pattern == pattern.name],\n",
    "                            verbose=False, plot=False)\n",
    "dfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 378
    },
    "id": "wSkT5tQIxYEJ",
    "outputId": "ee3e3e91-e660-4e45-f619-ce7b2b3bdb27"
   },
   "outputs": [],
   "source": [
    "# convert dfi to Seqlet objects and plot it\n",
    "from bpnet.modisco.pattern_instances import dfi2seqlets\n",
    "\n",
    "seqlets = [s.shift(-xlim[0]).set_seqname(f'Contrib {task}/profile/wn')\n",
    "         for s in dfi2seqlets(dfm, short_name=True)]\n",
    "\n",
    "plot_tracks(viz_dict,\n",
    "            fig_height_per_track=1,\n",
    "            fig_width=10,\n",
    "            seqlets=seqlets,\n",
    "            rotate_y=0);\n",
    "sns.despine(top=True, right=True, bottom=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o7HzZ4In1z5v"
   },
   "source": [
    "## Motif spacing visualization\n",
    "\n",
    "Here, we will visualize the motif spacing between the two Nanog motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "id": "Jam2jx9e27tu",
    "outputId": "634d4dbc-53c9-40e1-bb08-feb0721720e9"
   },
   "outputs": [],
   "source": [
    "from bpnet.modisco.files import ModiscoFile\n",
    "\n",
    "# Let's load the resulting table:\n",
    "dfi = pd.read_csv(modisco_dir / 'Nanog/motif-instances.tsv.gz', sep='\\t')\n",
    "# visualize spacing for Nanog/metacluster_0/pattern_0\n",
    "mf = ModiscoFile(modisco_dir / 'Nanog/modisco.h5')\n",
    "p = mf.get_pattern('metacluster_0/pattern_0')\n",
    "p.plot(['seq_ic', \"contrib\"], rotate_y=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "id": "0i2tLw0C4z5c",
    "outputId": "246bb2e1-99d2-41ef-b1e2-5e87e9625220"
   },
   "outputs": [],
   "source": [
    "# create a table of motif_paris\n",
    "from bpnet.modisco.pattern_instances import motif_pair_dfi  # main function for motif spacing\n",
    "\n",
    "\n",
    "dfi_subset = dfi[dfi.pattern == p.name]  # use only the first pattern\n",
    "dfi_subset['pattern_name'] = 'Nanog'  # motif_pair_dfi requires `pattern_name` column\n",
    "\n",
    "dfab = motif_pair_dfi(dfi_subset, ['Nanog', 'Nanog'])\n",
    "print(len(dfab))\n",
    "dfab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "bZu4SBiY5J0W",
    "outputId": "5ea80abc-5280-4469-a8a2-8faa523c171c"
   },
   "outputs": [],
   "source": [
    "plt.hist(dfab[dfab.strand_combination == \"++\"].center_diff, bins=np.arange(40)+0.5)\n",
    "plt.xlabel(\"Motif distance\")\n",
    "plt.ylabel(\"Frequency\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ckIo6oN11_3Z"
   },
   "source": [
    "## FAQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xzIwj1pc1yOl"
   },
   "source": [
    "### How do I score new regions not present in  the contribution file?\n",
    "\n",
    "\n",
    "If you would like to get motif instances for regions not present in the contribution file, the easiest is to first generate the contribution file for your regions of interest using `bpnet contrib ... --regions=regions.bed`  and then run `cwm-scan` with `--contrib-file` pointing to this new contribution file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HxDp6nRoFXOX"
   },
   "source": [
    "# Simulate motif spacing\n",
    "\n",
    "\n",
    "Showcase the `BPNet` model API\n",
    "    - visualize the locus with contrib scores + predictions\n",
    "    - motif spacing + simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "id": "-2_h0BifAs8L",
    "outputId": "1cbfbb53-d847-4728-9be3-54238898b880"
   },
   "outputs": [],
   "source": [
    "# Simulate Oct4-Sox2 and Nanog spacing\n",
    "from bpnet.BPNet import BPNetSeqModel\n",
    "\n",
    "bpn = BPNetSeqModel(sm)  # wrap SeqModel to BPNetSeqModel to get `sim_pred` method\n",
    "\n",
    "\n",
    "plot_tracks(bpn.sim_pred(central_motif='TTTGCATAACAA', side_motif='AGCCATCA', side_distances=[115]), \n",
    "            fig_height_per_track=1,\n",
    "            fig_width=10,\n",
    "            rotate_y=0,\n",
    "            title=\"distance = 15\");\n",
    "sns.despine(top=True, right=True, bottom=True)\n",
    "\n",
    "\n",
    "plot_tracks(bpn.sim_pred(central_motif='TTTGCATAACAA', side_motif='AGCCATCA', side_distances=[150]), \n",
    "            fig_height_per_track=1,\n",
    "            fig_width=10,\n",
    "            rotate_y=0,\n",
    "            title='distance = 50');\n",
    "sns.despine(top=True, right=True, bottom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "NgcQxhavB3Sp",
    "outputId": "7c3d7212-ef2d-44d9-a022-391ec01e39ce"
   },
   "outputs": [],
   "source": [
    "# run simulation for the whole range\n",
    "# quantify the profile height (profile/* features)\n",
    "from bpnet.simulate import generate_sim\n",
    "\n",
    "res = generate_sim(bpn, central_motif='AGCCATCA', side_motif='TTTGCATAACAA', side_distances=np.arange(110, 170), center_coords=[65, 135], contribution=[], correct=True)\n",
    "\n",
    "dfs, profiles = res\n",
    "dfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "m24sqs3GCb-a",
    "outputId": "e44343b4-57f9-449c-fc96-94740187f264"
   },
   "outputs": [],
   "source": [
    "from plotnine import *\n",
    "import plotnine\n",
    "\n",
    "plotnine.options.figure_size = (4, 2)\n",
    "(ggplot(aes(x='distance', y='profile/counts_max_ref_frac'), dfs[dfs.task=='Nanog']) + \n",
    " geom_line() + \n",
    " geom_hline(yintercept=1, alpha=0.5) + \n",
    " ylim([0, 2]) +\n",
    " theme_classic())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GG8Tmu914kcu"
   },
   "source": [
    "# FAQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ShuwEh6w4k6J"
   },
   "source": [
    "### I want to train a model on ChIP-seq. How can I do this?\n",
    "\n",
    "Follow the same procedure as for ChIP-nexus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Xe_QP7U4mHm"
   },
   "source": [
    "### I want to train a model on DNase-seq or ATAC-seq. How can I do this?\n",
    "\n",
    "The key difference between DNase-seq and ChIP-seq/exo is that DNase-seq coverage is not strand specific. Hence a single BigWig file is required. By contrast, ChIP-seq required two BigWigs - one for the positive and one for the negative strand. Beware that controlling for DNase biases is still an open question and you should think carefully about it.\n",
    "\n",
    "Otherwise, you can just specify a similar `dataspec.yml` as before:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S8IxbWrBy4iX"
   },
   "source": [
    "# Notes / Ideas\n",
    "\n",
    "- Allow the user to download the output files instead of running the model by adding an if else in each chapter\n",
    "  - e.g. make each chapter independent of each other\n",
    "  - required files:\n",
    "    - contrib: `seq_model.pkl`, `config.gin.json`, `dataspec.yml`\n",
    "    - modisco-run: `contrib_file`, `null_contrib_file`\n",
    "    - cwm-scan: `modisco.h5`, `modisco-run.subset-contrib-file.npy`, `modisco-run.kwargs.json`\n",
    "    - reports: ...?\n",
    "- bpnet \n",
    "- [ ] go through all the paper notebooks and list useful things to show\n",
    "  - how do I visualize a particular locus with all the motif instances + contrib scores?\n",
    "- [ ] shall we rename `example->regions` in dfi?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qwoRxJmHlPC0"
   },
   "outputs": [],
   "source": [
    "# Export the generated files\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zaQlXaRxkX8A"
   },
   "outputs": [],
   "source": [
    "# bpnet_demo_dir = '/gdrive/My\\ Drive/projects/chipnexus/data/bpnet-demo'\n",
    "# !mkdir -p {bpnet_demo_dir}\n",
    "# !cp -R {model_dir} {bpnet_demo_dir}/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "“bpnet”的副本",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
